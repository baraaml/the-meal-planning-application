Directory Tree: ./
================================================================================

├── .env

////////////////////////////////////////////////////////////////////////////////
# Database settings
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/mealflow

# API settings
API_HOST=0.0.0.0
API_PORT=8000
RELOAD=True

# Embedding model settings
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Recommendation settings
DEFAULT_RECOMMENDATION_LIMIT=10
CONTENT_TYPES=meal,recipe
ALLOWED_TRENDING_WINDOWS=day,week,month
INTERACTION_TYPES=view,like,save,cook,comment

# Scheduler settings
EMBEDDING_GENERATION_INTERVAL=60
SCHEDULER_SLEEP_INTERVAL=60

# Client settings
RECOMMENDATION_API_URL=http://localhost:8000

# Cache settings
ENABLE_CACHE=False
CACHE_EXPIRATION=300

# Similarity thresholds
MIN_SIMILARITY_SCORE=0.6
MIN_COMMON_ITEMS=2

# Logging configuration
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# Data import settings
DATA_DIR=data
RECIPE_GENERAL_FILE=RecipeDB_general.csv
RECIPE_INGREDIENT_PHRASE_FILE=RecipeDB_ingredient_phrase.csv
RECIPE_INGREDIENT_FLAVOR_FILE=RecipeDB_ingredient_flavor.csv
RECIPE_INSTRUCTIONS_FILE=RecipeDB_instructions.json
MERGED_RECIPES_FILE=merged.csv
BATCH_SIZE=1000
////////////////////////////////////////////////////////////////////////////////

├── .env.example

////////////////////////////////////////////////////////////////////////////////
# Database settings
DATABASE_URL=postgresql://username:password@localhost:5432/database_name

# API settings
API_HOST=0.0.0.0
API_PORT=8000
RELOAD=True

# Embedding model settings
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Recommendation settings
DEFAULT_RECOMMENDATION_LIMIT=10
CONTENT_TYPES=meal,recipe
ALLOWED_TRENDING_WINDOWS=day,week,month
INTERACTION_TYPES=view,like,save,cook,comment

# Scheduler settings
EMBEDDING_GENERATION_INTERVAL=60
SCHEDULER_SLEEP_INTERVAL=60

# Client settings
RECOMMENDATION_API_URL=http://localhost:8000

# Cache settings
ENABLE_CACHE=False
CACHE_EXPIRATION=300

# Similarity thresholds
MIN_SIMILARITY_SCORE=0.6
MIN_COMMON_ITEMS=2

# Logging configuration
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# Data import settings
DATA_DIR=data
RECIPE_GENERAL_FILE=RecipeDB_general.csv
RECIPE_INGREDIENT_PHRASE_FILE=RecipeDB_ingredient_phrase.csv
RECIPE_INGREDIENT_FLAVOR_FILE=RecipeDB_ingredient_flavor.csv
RECIPE_INSTRUCTIONS_FILE=RecipeDB_instructions.json
MERGED_RECIPES_FILE=merged.csv
BATCH_SIZE=1000
////////////////////////////////////////////////////////////////////////////////

├── Makefile

////////////////////////////////////////////////////////////////////////////////
.PHONY: setup install clean run test lint load-data setup-db init-embeddings

# Default Python interpreter
PYTHON = python3
PIP = pip3

# Default environment file
ENV_FILE = .env

# Check if environment file exists
ifeq (,$(wildcard $(ENV_FILE)))
    $(warning $(ENV_FILE) file not found. Using default values.)
endif

# Load environment variables if file exists
ifneq (,$(wildcard $(ENV_FILE)))
    include $(ENV_FILE)
    export
endif

# Default variables
DATABASE_URL ?= postgresql://postgres:postgres@localhost:5432/mealflow
API_PORT ?= 8000
API_HOST ?= 0.0.0.0

# Setup the development environment
setup: install setup-db load-data init-embeddings

# Install required packages
install:
	@echo "Installing required packages..."
	$(PIP) install -r requirements.txt

# Clean up temporary files and artifacts
clean:
	@echo "Cleaning up temporary files and artifacts..."
	find . -type d -name __pycache__ -exec rm -rf {} +
	find . -type f -name "*.pyc" -delete
	find . -type f -name "*.pyo" -delete
	find . -type f -name "*.pyd" -delete
	find . -type f -name ".DS_Store" -delete
	find . -type d -name "*.egg-info" -exec rm -rf {} +
	find . -type d -name "*.egg" -exec rm -rf {} +
	find . -type d -name ".pytest_cache" -exec rm -rf {} +
	find . -type d -name ".coverage" -exec rm -rf {} +
	find . -type d -name "htmlcov" -exec rm -rf {} +
	find . -type d -name ".mypy_cache" -exec rm -rf {} +

# Run the service
run:
	@echo "Starting the meal recommendation service..."
	uvicorn main:app --host $(API_HOST) --port $(API_PORT) --reload

# Run tests
test:
	@echo "Running tests..."
	pytest -xvs tests/

# Run linter
lint:
	@echo "Running linter..."
	flake8 .

# Load data from CSV and JSON files
load-data:
	@echo "Loading data from CSV and JSON files..."
	$(PYTHON) -m data.loader

# Setup database tables for recommendation system
setup-db:
	@echo "Setting up database tables for recommendation system..."
	$(PYTHON) -m setup

# Generate initial embeddings
init-embeddings:
	@echo "Generating initial embeddings..."
	$(PYTHON) -c "from embeddings.generator import EmbeddingGenerator; \
				  generator = EmbeddingGenerator(); \
				  result = generator.generate_all_embeddings(); \
				  print(f'Initial embeddings generated: {result}')"

# Test database connection
test-db:
	@echo "Testing database connection..."
	$(PYTHON) -c "from data.database import test_connection; test_connection()"

# Setup database schema only (no data import)
schema-only:
	@echo "Setting up database schema only..."
	$(PYTHON) -m setup

# Generate requirements.txt file
freeze:
	@echo "Generating requirements.txt file..."
	$(PIP) freeze > requirements.txt

# Help
help:
	@echo "Available targets:"
	@echo "  setup          - Set up development environment (install, setup-db, load-data, init-embeddings)"
	@echo "  install        - Install required packages"
	@echo "  clean          - Clean up temporary files and artifacts"
	@echo "  run            - Run the meal recommendation service"
	@echo "  test           - Run tests"
	@echo "  lint           - Run linter"
	@echo "  load-data      - Load data from CSV and JSON files"
	@echo "  setup-db       - Setup database tables for recommendation system"
	@echo "  init-embeddings - Generate initial embeddings"
	@echo "  test-db        - Test database connection"
	@echo "  schema-only    - Setup database schema only (no data import)"
	@echo "  freeze         - Generate requirements.txt file"
	@echo "  help           - Show this help"
////////////////////////////////////////////////////////////////////////////////

├── __init__.py

////////////////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////////////////

├── api
│   ├── __init__.py

////////////////////////////////////////////////////////////////////////////////
"""
Recommendation Service API Package.
"""
# This file enables the directory to be imported as a package
////////////////////////////////////////////////////////////////////////////////

│   ├── endpoints.py

////////////////////////////////////////////////////////////////////////////////
"""
Meal Recommendation Service API endpoints.
All API routes are defined here in a modular, organized manner.
"""
from fastapi import APIRouter, Depends, Query, HTTPException, status, Request
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import time

from config import CONTENT_TYPES, DEFAULT_RECOMMENDATION_LIMIT, ALLOWED_TRENDING_WINDOWS
from data.database import get_db
from services.hybrid import HybridRecommender
from services.item_based import ItemBasedRecommender
from services.collaborative import CollaborativeRecommender
from services.content_based import ContentBasedRecommender
from services.popularity import PopularityRecommender

# Request & Response Models
class InteractionCreate(BaseModel):
    """Request model for creating a meal interaction record."""
    user_id: str
    meal_id: str
    content_type: str
    interaction_type: str

class RecommendationItem(BaseModel):
    """Model for a recommendation item in responses."""
    id: str
    content_type: str
    title: str
    score: Optional[float] = None
    
class RecommendationResponse(BaseModel):
    """Standard response model for recommendation endpoints."""
    items: List[RecommendationItem]
    count: int
    execution_time_ms: float

# API Routers
router = APIRouter()

# Utility functions
def validate_content_type(content_type: str, allow_all: bool = False) -> str:
    """Validate the content type parameter."""
    valid_types = CONTENT_TYPES.copy()
    if allow_all:
        valid_types.append('all')
        
    if content_type not in valid_types:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Content type must be one of: {', '.join(valid_types)}"
        )
    
    return content_type

# Request timing middleware
@router.middleware("http")
async def add_process_time_header(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    
    # If it's a JSON response, we add the execution time to the response
    if isinstance(response, JSONResponse):
        content = response.body.decode()
        import json
        try:
            data = json.loads(content)
            if isinstance(data, dict):
                data["execution_time_ms"] = round(process_time * 1000, 2)
                response.body = json.dumps(data).encode()
        except:
            pass
    
    return response

# Endpoints
@router.get("/", tags=["status"])
def read_root():
    """Root endpoint for API status check."""
    return {"status": "Meal recommendation service is running"}

@router.get("/recommend/user/{user_id}", response_model=RecommendationResponse)
def get_user_recommendations(
    user_id: str,
    content_type: Optional[str] = Query(None, description="Filter by content type (meal, recipe)"),
    limit: int = Query(DEFAULT_RECOMMENDATION_LIMIT, description="Maximum number of recommendations"),
    recommendation_type: str = Query("hybrid", description="Recommendation algorithm to use (hybrid, item-based, user-based)"),
    cuisine: Optional[str] = Query(None, description="Filter by cuisine type"),
    dietary_restriction: Optional[str] = Query(None, description="Filter by dietary restriction"),
    db = Depends(get_db)
):
    """Get personalized meal recommendations for a user."""
    start_time = time.time()
    
    # Validate content type if provided
    if content_type:
        content_type = validate_content_type(content_type)
    
    # Choose the recommendation strategy based on the type parameter
    if recommendation_type == "hybrid":
        recommender = HybridRecommender()
    elif recommendation_type == "item-based":
        recommender = ItemBasedRecommender()
    elif recommendation_type == "user-based":
        recommender = CollaborativeRecommender()
    else:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Invalid recommendation type. Must be 'hybrid', 'item-based', or 'user-based'."
        )
    
    # Get recommendations
    recommended_items = recommender.get_recommendations(
        user_id=user_id,
        content_type=content_type,
        limit=limit,
        cuisine=cuisine,
        dietary_restriction=dietary_restriction
    )
    
    # Format response
    items = []
    for item in recommended_items:
        items.append(RecommendationItem(
            id=item["id"],
            content_type=item["content_type"],
            title=item.get("title", ""),
            score=item.get("score")
        ))
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "items": items,
        "count": len(items),
        "execution_time_ms": round(execution_time, 2)
    }

@router.get("/recommend/similar/{content_type}/{meal_id}", response_model=RecommendationResponse)
def get_similar_meals(
    content_type: str,
    meal_id: str,
    limit: int = Query(DEFAULT_RECOMMENDATION_LIMIT, description="Maximum number of similar meals"),
    similarity_method: str = Query("content", description="Method to determine similarity (content, interaction, ingredient)"),
    db = Depends(get_db)
):
    """Get meals similar to the specified item."""
    start_time = time.time()
    
    # Validate content type
    content_type = validate_content_type(content_type)
    
    # Choose similarity method
    if similarity_method == "content":
        # Content-based similarity using vector embeddings
        recommender = ContentBasedRecommender()
    elif similarity_method == "interaction":
        # Item-based collaborative filtering using interaction patterns
        recommender = ItemBasedRecommender()
    elif similarity_method == "ingredient":
        # Ingredient-based similarity
        recommender = ContentBasedRecommender()
        similar_items = recommender.get_similar_by_ingredients(
            meal_id=meal_id,
            content_type=content_type,
            limit=limit
        )
        
        # Format the items and return
        items = []
        for item in similar_items:
            items.append(RecommendationItem(
                id=item["id"],
                content_type=item.get("content_type", content_type),
                title=item.get("title", ""),
                score=item.get("similarity") or item.get("score")
            ))
        
        execution_time = (time.time() - start_time) * 1000
        
        return {
            "items": items,
            "count": len(items),
            "execution_time_ms": round(execution_time, 2)
        }
    else:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Invalid similarity method. Must be 'content', 'interaction', or 'ingredient'."
        )
    
    # Get similar meals
    similar_items = recommender.get_recommendations(
        meal_id=meal_id,
        content_type=content_type,
        limit=limit
    )
    
    # Format the items
    items = []
    for item in similar_items:
        items.append(RecommendationItem(
            id=item["id"],
            content_type=item["content_type"],
            title=item.get("title", ""),
            score=item.get("similarity") or item.get("score")
        ))
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "items": items,
        "count": len(items),
        "execution_time_ms": round(execution_time, 2)
    }

@router.get("/trending/{content_type}", response_model=RecommendationResponse)
def get_trending_meals(
    content_type: str,
    time_window: str = Query("day", description="Time window for trending meals"),
    limit: int = Query(DEFAULT_RECOMMENDATION_LIMIT, description="Maximum number of items"),
    db = Depends(get_db)
):
    """Get trending meals based on recent interactions."""
    start_time = time.time()
    
    # Validate content type (allowing 'all' as a valid option)
    content_type = validate_content_type(content_type, allow_all=True)
    
    # Validate time window
    if time_window not in ALLOWED_TRENDING_WINDOWS:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Time window must be one of: {', '.join(ALLOWED_TRENDING_WINDOWS)}"
        )
    
    # Get trending meals
    recommender = PopularityRecommender()
    trending_items = recommender.get_recommendations(
        content_type=content_type,
        time_window=time_window,
        limit=limit
    )
    
    # Format the items
    items = []
    for item in trending_items:
        items.append(RecommendationItem(
            id=item["id"],
            content_type=item["content_type"],
            title=item.get("title", ""),
            score=item.get("popularity")
        ))
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "items": items,
        "count": len(items),
        "execution_time_ms": round(execution_time, 2)
    }

@router.get("/recommend/cuisine/{cuisine_id}", response_model=RecommendationResponse)
def get_cuisine_recommendations(
    cuisine_id: str,
    limit: int = Query(DEFAULT_RECOMMENDATION_LIMIT, description="Maximum number of items"),
    db = Depends(get_db)
):
    """Get meal recommendations based on cuisine."""
    start_time = time.time()
    
    recommender = PopularityRecommender()
    cuisine_items = recommender.get_cuisine_recommendations(
        cuisine_id=cuisine_id,
        limit=limit
    )
    
    # Format the items
    items = []
    for item in cuisine_items:
        items.append(RecommendationItem(
            id=item["id"],
            content_type=item.get("content_type", "meal"),
            title=item.get("title", ""),
            score=None
        ))
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "items": items,
        "count": len(items),
        "execution_time_ms": round(execution_time, 2)
    }

@router.get("/recommend/dietary/{dietary_restriction_id}", response_model=RecommendationResponse)
def get_dietary_recommendations(
    dietary_restriction_id: str,
    limit: int = Query(DEFAULT_RECOMMENDATION_LIMIT, description="Maximum number of items"),
    db = Depends(get_db)
):
    """Get meal recommendations based on dietary restrictions."""
    start_time = time.time()
    
    recommender = PopularityRecommender()
    dietary_items = recommender.get_dietary_recommendations(
        dietary_restriction_id=dietary_restriction_id,
        limit=limit
    )
    
    # Format the items
    items = []
    for item in dietary_items:
        items.append(RecommendationItem(
            id=item["id"],
            content_type=item.get("content_type", "meal"),
            title=item.get("title", ""),
            score=None
        ))
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "items": items,
        "count": len(items),
        "execution_time_ms": round(execution_time, 2)
    }

@router.post("/interactions")
def record_interaction(interaction: InteractionCreate, db = Depends(get_db)):
    """Record a user interaction with a meal."""
    start_time = time.time()
    
    # Validate content type
    try:
        validate_content_type(interaction.content_type)
    except HTTPException as e:
        raise e
    
    from data.repositories import InteractionRepository
    
    # Record the interaction
    repository = InteractionRepository()
    success = repository.record_interaction(
        user_id=interaction.user_id,
        meal_id=interaction.meal_id,
        content_type=interaction.content_type,
        interaction_type=interaction.interaction_type
    )
    
    if not success:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to record interaction"
        )
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "status": "recorded",
        "execution_time_ms": round(execution_time, 2)
    }

@router.get("/user/{user_id}/history")
def get_user_meal_history(
    user_id: str,
    content_type: Optional[str] = None,
    limit: int = 10,
    db = Depends(get_db)
):
    """Get a user's meal interaction history."""
    start_time = time.time()
    
    # Validate content type if provided
    if content_type:
        content_type = validate_content_type(content_type)
    
    from data.repositories import InteractionRepository
    
    repository = InteractionRepository()
    history = repository.get_user_recent_interactions(
        user_id=user_id,
        content_type=content_type,
        limit=limit
    )
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "history": history,
        "count": len(history),
        "execution_time_ms": round(execution_time, 2)
    }

@router.get("/user/{user_id}/dietary-preferences")
def get_user_dietary_preferences(
    user_id: str,
    db = Depends(get_db)
):
    """Get a user's dietary preferences."""
    start_time = time.time()
    
    from data.repositories import InteractionRepository
    
    repository = InteractionRepository()
    preferences = repository.get_user_dietary_preferences(user_id)
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "dietary_preferences": preferences,
        "count": len(preferences),
        "execution_time_ms": round(execution_time, 2)
    }

@router.post("/user/{user_id}/dietary-preferences")
def set_user_dietary_preference(
    user_id: str,
    dietary_restriction_id: int,
    db = Depends(get_db)
):
    """Add a dietary preference for a user."""
    start_time = time.time()
    
    from data.repositories import InteractionRepository
    
    repository = InteractionRepository()
    success = repository.add_user_dietary_preference(
        user_id=user_id,
        dietary_restriction_id=dietary_restriction_id
    )
    
    if not success:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to add dietary preference"
        )
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "status": "added",
        "execution_time_ms": round(execution_time, 2)
    }
////////////////////////////////////////////////////////////////////////////////

│   └── middleware.py

////////////////////////////////////////////////////////////////////////////////
"""
API middleware for the meal recommendation service.
Includes CORS, request timing, and error handling middleware.
"""
from fastapi import Request, Response
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
import time
import json
import logging
from typing import Callable

logger = logging.getLogger(__name__)

def setup_middleware(app):
    """
    Set up middleware for the FastAPI application.
    
    Args:
        app: The FastAPI application
    """
    # Add CORS middleware
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],  # Replace with specific origins in production
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    
    # Add GZip compression middleware
    app.add_middleware(GZipMiddleware, minimum_size=1000)
    
    # Add request timing middleware
    @app.middleware("http")
    async def add_process_time_header(request: Request, call_next: Callable):
        start_time = time.time()
        
        # Add request ID for tracking
        request_id = f"req-{int(start_time * 1000)}"
        request.state.request_id = request_id
        
        # Process the request
        try:
            response = await call_next(request)
            process_time = time.time() - start_time
            
            # Add timing headers
            response.headers["X-Process-Time"] = str(round(process_time * 1000, 2))
            response.headers["X-Request-ID"] = request_id
            
            # Add timing to JSON response
            if (
                response.headers.get("content-type") == "application/json" 
                and isinstance(response, JSONResponse)
            ):
                content = response.body.decode()
                try:
                    data = json.loads(content)
                    if isinstance(data, dict):
                        data["execution_time_ms"] = round(process_time * 1000, 2)
                        data["request_id"] = request_id
                        response.body = json.dumps(data).encode()
                except Exception as e:
                    logger.error(f"Error updating response: {e}")
            
            # Log request completion
            logger.info(
                f"Request {request_id} completed: {request.method} {request.url.path} "
                f"- {response.status_code} in {process_time:.3f}s"
            )
            
            return response
            
        except Exception as e:
            # Log any unhandled exceptions
            process_time = time.time() - start_time
            logger.error(
                f"Request {request_id} error: {request.method} {request.url.path} "
                f"- {str(e)} in {process_time:.3f}s"
            )
            
            # Create error response
            error_response = JSONResponse(
                status_code=500,
                content={
                    "detail": "Internal server error",
                    "request_id": request_id,
                    "execution_time_ms": round(process_time * 1000, 2)
                }
            )
            return error_response
    
    # Add error logging middleware
    @app.middleware("http")
    async def log_errors(request: Request, call_next: Callable):
        try:
            return await call_next(request)
        except Exception as e:
            # Log the error
            logger.exception(f"Unhandled exception: {str(e)}")
            
            # Return a consistent error response
            return JSONResponse(
                status_code=500,
                content={
                    "detail": "Internal server error",
                    "type": type(e).__name__,
                    "request_id": getattr(request.state, "request_id", "unknown")
                }
            )
////////////////////////////////////////////////////////////////////////////////

├── chat.txt

////////////////////////////////////////////////////////////////////////////////
Directory Tree: ./
================================================================================

├── .env

////////////////////////////////////////////////////////////////////////////////
# Database settings
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/mealflow

# API settings
API_HOST=0.0.0.0
API_PORT=8000
RELOAD=True

# Embedding model settings
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Recommendation settings
DEFAULT_RECOMMENDATION_LIMIT=10
CONTENT_TYPES=meal,recipe
ALLOWED_TRENDING_WINDOWS=day,week,month
INTERACTION_TYPES=view,like,save,cook,comment

# Scheduler settings
EMBEDDING_GENERATION_INTERVAL=60
SCHEDULER_SLEEP_INTERVAL=60

# Client settings
RECOMMENDATION_API_URL=http://localhost:8000

# Cache settings
ENABLE_CACHE=False
CACHE_EXPIRATION=300

# Similarity thresholds
MIN_SIMILARITY_SCORE=0.6
MIN_COMMON_ITEMS=2

# Logging configuration
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# Data import settings
DATA_DIR=data
RECIPE_GENERAL_FILE=RecipeDB_general.csv
RECIPE_INGREDIENT_PHRASE_FILE=RecipeDB_ingredient_phrase.csv
RECIPE_INGREDIENT_FLAVOR_FILE=RecipeDB_ingredient_flavor.csv
RECIPE_INSTRUCTIONS_FILE=RecipeDB_instructions.json
MERGED_RECIPES_FILE=merged.csv
BATCH_SIZE=1000
////////////////////////////////////////////////////////////////////////////////

├── .env.example

////////////////////////////////////////////////////////////////////////////////
# Database settings
DATABASE_URL=postgresql://username:password@localhost:5432/database_name

# API settings
API_HOST=0.0.0.0
API_PORT=8000
RELOAD=True

# Embedding model settings
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Recommendation settings
DEFAULT_RECOMMENDATION_LIMIT=10
CONTENT_TYPES=meal,recipe
ALLOWED_TRENDING_WINDOWS=day,week,month
INTERACTION_TYPES=view,like,save,cook,comment

# Scheduler settings
EMBEDDING_GENERATION_INTERVAL=60
SCHEDULER_SLEEP_INTERVAL=60

# Client settings
RECOMMENDATION_API_URL=http://localhost:8000

# Cache settings
ENABLE_CACHE=False
CACHE_EXPIRATION=300

# Similarity thresholds
MIN_SIMILARITY_SCORE=0.6
MIN_COMMON_ITEMS=2

# Logging configuration
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# Data import settings
DATA_DIR=data
RECIPE_GENERAL_FILE=RecipeDB_general.csv
RECIPE_INGREDIENT_PHRASE_FILE=RecipeDB_ingredient_phrase.csv
RECIPE_INGREDIENT_FLAVOR_FILE=RecipeDB_ingredient_flavor.csv
RECIPE_INSTRUCTIONS_FILE=RecipeDB_instructions.json
MERGED_RECIPES_FILE=merged.csv
BATCH_SIZE=1000
////////////////////////////////////////////////////////////////////////////////

├── Makefile

////////////////////////////////////////////////////////////////////////////////
.PHONY: setup install clean run test lint load-data setup-db init-embeddings

# Default Python interpreter
PYTHON = python3
PIP = pip3

# Default environment file
ENV_FILE = .env

# Check if environment file exists
ifeq (,$(wildcard $(ENV_FILE)))
    $(warning $(ENV_FILE) file not found. Using default values.)
endif

# Load environment variables if file exists
ifneq (,$(wildcard $(ENV_FILE)))
    include $(ENV_FILE)
    export
endif

# Default variables
DATABASE_URL ?= postgresql://postgres:postgres@localhost:5432/mealflow
API_PORT ?= 8000
API_HOST ?= 0.0.0.0

# Setup the development environment
setup: install setup-db load-data init-embeddings

# Install required packages
install:
	@echo "Installing required packages..."
	$(PIP) install -r requirements.txt

# Clean up temporary files and artifacts
clean:
	@echo "Cleaning up temporary files and artifacts..."
	find . -type d -name __pycache__ -exec rm -rf {} +
	find . -type f -name "*.pyc" -delete
	find . -type f -name "*.pyo" -delete
	find . -type f -name "*.pyd" -delete
	find . -type f -name ".DS_Store" -delete
	find . -type d -name "*.egg-info" -exec rm -rf {} +
	find . -type d -name "*.egg" -exec rm -rf {} +
	find . -type d -name ".pytest_cache" -exec rm -rf {} +
	find . -type d -name ".coverage" -exec rm -rf {} +
	find . -type d -name "htmlcov" -exec rm -rf {} +
	find . -type d -name ".mypy_cache" -exec rm -rf {} +

# Run the service
run:
	@echo "Starting the meal recommendation service..."
	uvicorn main:app --host $(API_HOST) --port $(API_PORT) --reload

# Run tests
test:
	@echo "Running tests..."
	pytest -xvs tests/

# Run linter
lint:
	@echo "Running linter..."
	flake8 .

# Load data from CSV and JSON files
load-data:
	@echo "Loading data from CSV and JSON files..."
	$(PYTHON) -m data.loader

# Setup database tables for recommendation system
setup-db:
	@echo "Setting up database tables for recommendation system..."
	$(PYTHON) -m setup

# Generate initial embeddings
init-embeddings:
	@echo "Generating initial embeddings..."
	$(PYTHON) -c "from embeddings.generator import EmbeddingGenerator; \
				  generator = EmbeddingGenerator(); \
				  result = generator.generate_all_embeddings(); \
				  print(f'Initial embeddings generated: {result}')"

# Test database connection
test-db:
	@echo "Testing database connection..."
	$(PYTHON) -c "from data.database import test_connection; test_connection()"

# Setup database schema only (no data import)
schema-only:
	@echo "Setting up database schema only..."
	$(PYTHON) -m setup

# Generate requirements.txt file
freeze:
	@echo "Generating requirements.txt file..."
	$(PIP) freeze > requirements.txt

# Help
help:
	@echo "Available targets:"
	@echo "  setup          - Set up development environment (install, setup-db, load-data, init-embeddings)"
	@echo "  install        - Install required packages"
	@echo "  clean          - Clean up temporary files and artifacts"
	@echo "  run            - Run the meal recommendation service"
	@echo "  test           - Run tests"
	@echo "  lint           - Run linter"
	@echo "  load-data      - Load data from CSV and JSON files"
	@echo "  setup-db       - Setup database tables for recommendation system"
	@echo "  init-embeddings - Generate initial embeddings"
	@echo "  test-db        - Test database connection"
	@echo "  schema-only    - Setup database schema only (no data import)"
	@echo "  freeze         - Generate requirements.txt file"
	@echo "  help           - Show this help"
////////////////////////////////////////////////////////////////////////////////

├── __init__.py

////////////////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////////////////

├── api
│   ├── __init__.py

////////////////////////////////////////////////////////////////////////////////
"""
Recommendation Service API Package.
"""
# This file enables the directory to be imported as a package
////////////////////////////////////////////////////////////////////////////////

│   ├── endpoints.py

////////////////////////////////////////////////////////////////////////////////
"""
Meal Recommendation Service API endpoints.
All API routes are defined here in a modular, organized manner.
"""
from fastapi import APIRouter, Depends, Query, HTTPException, status, Request
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import time

from config import CONTENT_TYPES, DEFAULT_RECOMMENDATION_LIMIT, ALLOWED_TRENDING_WINDOWS
from data.database import get_db
from services.hybrid import HybridRecommender
from services.item_based import ItemBasedRecommender
from services.collaborative import CollaborativeRecommender
from services.content_based import ContentBasedRecommender
from services.popularity import PopularityRecommender

# Request & Response Models
class InteractionCreate(BaseModel):
    """Request model for creating a meal interaction record."""
    user_id: str
    meal_id: str
    content_type: str
    interaction_type: str

class RecommendationItem(BaseModel):
    """Model for a recommendation item in responses."""
    id: str
    content_type: str
    title: str
    score: Optional[float] = None
    
class RecommendationResponse(BaseModel):
    """Standard response model for recommendation endpoints."""
    items: List[RecommendationItem]
    count: int
    execution_time_ms: float

# API Routers
router = APIRouter()

# Utility functions
def validate_content_type(content_type: str, allow_all: bool = False) -> str:
    """Validate the content type parameter."""
    valid_types = CONTENT_TYPES.copy()
    if allow_all:
        valid_types.append('all')
        
    if content_type not in valid_types:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Content type must be one of: {', '.join(valid_types)}"
        )
    
    return content_type

# Request timing middleware
@router.middleware("http")
async def add_process_time_header(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    
    # If it's a JSON response, we add the execution time to the response
    if isinstance(response, JSONResponse):
        content = response.body.decode()
        import json
        try:
            data = json.loads(content)
            if isinstance(data, dict):
                data["execution_time_ms"] = round(process_time * 1000, 2)
                response.body = json.dumps(data).encode()
        except:
            pass
    
    return response

# Endpoints
@router.get("/", tags=["status"])
def read_root():
    """Root endpoint for API status check."""
    return {"status": "Meal recommendation service is running"}

@router.get("/recommend/user/{user_id}", response_model=RecommendationResponse)
def get_user_recommendations(
    user_id: str,
    content_type: Optional[str] = Query(None, description="Filter by content type (meal, recipe)"),
    limit: int = Query(DEFAULT_RECOMMENDATION_LIMIT, description="Maximum number of recommendations"),
    recommendation_type: str = Query("hybrid", description="Recommendation algorithm to use (hybrid, item-based, user-based)"),
    cuisine: Optional[str] = Query(None, description="Filter by cuisine type"),
    dietary_restriction: Optional[str] = Query(None, description="Filter by dietary restriction"),
    db = Depends(get_db)
):
    """Get personalized meal recommendations for a user."""
    start_time = time.time()
    
    # Validate content type if provided
    if content_type:
        content_type = validate_content_type(content_type)
    
    # Choose the recommendation strategy based on the type parameter
    if recommendation_type == "hybrid":
        recommender = HybridRecommender()
    elif recommendation_type == "item-based":
        recommender = ItemBasedRecommender()
    elif recommendation_type == "user-based":
        recommender = CollaborativeRecommender()
    else:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Invalid recommendation type. Must be 'hybrid', 'item-based', or 'user-based'."
        )
    
    # Get recommendations
    recommended_items = recommender.get_recommendations(
        user_id=user_id,
        content_type=content_type,
        limit=limit,
        cuisine=cuisine,
        dietary_restriction=dietary_restriction
    )
    
    # Format response
    items = []
    for item in recommended_items:
        items.append(RecommendationItem(
            id=item["id"],
            content_type=item["content_type"],
            title=item.get("title", ""),
            score=item.get("score")
        ))
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "items": items,
        "count": len(items),
        "execution_time_ms": round(execution_time, 2)
    }

@router.get("/recommend/similar/{content_type}/{meal_id}", response_model=RecommendationResponse)
def get_similar_meals(
    content_type: str,
    meal_id: str,
    limit: int = Query(DEFAULT_RECOMMENDATION_LIMIT, description="Maximum number of similar meals"),
    similarity_method: str = Query("content", description="Method to determine similarity (content, interaction, ingredient)"),
    db = Depends(get_db)
):
    """Get meals similar to the specified item."""
    start_time = time.time()
    
    # Validate content type
    content_type = validate_content_type(content_type)
    
    # Choose similarity method
    if similarity_method == "content":
        # Content-based similarity using vector embeddings
        recommender = ContentBasedRecommender()
    elif similarity_method == "interaction":
        # Item-based collaborative filtering using interaction patterns
        recommender = ItemBasedRecommender()
    elif similarity_method == "ingredient":
        # Ingredient-based similarity
        recommender = ContentBasedRecommender()
        similar_items = recommender.get_similar_by_ingredients(
            meal_id=meal_id,
            content_type=content_type,
            limit=limit
        )
        
        # Format the items and return
        items = []
        for item in similar_items:
            items.append(RecommendationItem(
                id=item["id"],
                content_type=item.get("content_type", content_type),
                title=item.get("title", ""),
                score=item.get("similarity") or item.get("score")
            ))
        
        execution_time = (time.time() - start_time) * 1000
        
        return {
            "items": items,
            "count": len(items),
            "execution_time_ms": round(execution_time, 2)
        }
    else:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Invalid similarity method. Must be 'content', 'interaction', or 'ingredient'."
        )
    
    # Get similar meals
    similar_items = recommender.get_recommendations(
        meal_id=meal_id,
        content_type=content_type,
        limit=limit
    )
    
    # Format the items
    items = []
    for item in similar_items:
        items.append(RecommendationItem(
            id=item["id"],
            content_type=item["content_type"],
            title=item.get("title", ""),
            score=item.get("similarity") or item.get("score")
        ))
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "items": items,
        "count": len(items),
        "execution_time_ms": round(execution_time, 2)
    }

@router.get("/trending/{content_type}", response_model=RecommendationResponse)
def get_trending_meals(
    content_type: str,
    time_window: str = Query("day", description="Time window for trending meals"),
    limit: int = Query(DEFAULT_RECOMMENDATION_LIMIT, description="Maximum number of items"),
    db = Depends(get_db)
):
    """Get trending meals based on recent interactions."""
    start_time = time.time()
    
    # Validate content type (allowing 'all' as a valid option)
    content_type = validate_content_type(content_type, allow_all=True)
    
    # Validate time window
    if time_window not in ALLOWED_TRENDING_WINDOWS:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Time window must be one of: {', '.join(ALLOWED_TRENDING_WINDOWS)}"
        )
    
    # Get trending meals
    recommender = PopularityRecommender()
    trending_items = recommender.get_recommendations(
        content_type=content_type,
        time_window=time_window,
        limit=limit
    )
    
    # Format the items
    items = []
    for item in trending_items:
        items.append(RecommendationItem(
            id=item["id"],
            content_type=item["content_type"],
            title=item.get("title", ""),
            score=item.get("popularity")
        ))
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "items": items,
        "count": len(items),
        "execution_time_ms": round(execution_time, 2)
    }

@router.get("/recommend/cuisine/{cuisine_id}", response_model=RecommendationResponse)
def get_cuisine_recommendations(
    cuisine_id: str,
    limit: int = Query(DEFAULT_RECOMMENDATION_LIMIT, description="Maximum number of items"),
    db = Depends(get_db)
):
    """Get meal recommendations based on cuisine."""
    start_time = time.time()
    
    recommender = PopularityRecommender()
    cuisine_items = recommender.get_cuisine_recommendations(
        cuisine_id=cuisine_id,
        limit=limit
    )
    
    # Format the items
    items = []
    for item in cuisine_items:
        items.append(RecommendationItem(
            id=item["id"],
            content_type=item.get("content_type", "meal"),
            title=item.get("title", ""),
            score=None
        ))
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "items": items,
        "count": len(items),
        "execution_time_ms": round(execution_time, 2)
    }

@router.get("/recommend/dietary/{dietary_restriction_id}", response_model=RecommendationResponse)
def get_dietary_recommendations(
    dietary_restriction_id: str,
    limit: int = Query(DEFAULT_RECOMMENDATION_LIMIT, description="Maximum number of items"),
    db = Depends(get_db)
):
    """Get meal recommendations based on dietary restrictions."""
    start_time = time.time()
    
    recommender = PopularityRecommender()
    dietary_items = recommender.get_dietary_recommendations(
        dietary_restriction_id=dietary_restriction_id,
        limit=limit
    )
    
    # Format the items
    items = []
    for item in dietary_items:
        items.append(RecommendationItem(
            id=item["id"],
            content_type=item.get("content_type", "meal"),
            title=item.get("title", ""),
            score=None
        ))
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "items": items,
        "count": len(items),
        "execution_time_ms": round(execution_time, 2)
    }

@router.post("/interactions")
def record_interaction(interaction: InteractionCreate, db = Depends(get_db)):
    """Record a user interaction with a meal."""
    start_time = time.time()
    
    # Validate content type
    try:
        validate_content_type(interaction.content_type)
    except HTTPException as e:
        raise e
    
    from data.repositories import InteractionRepository
    
    # Record the interaction
    repository = InteractionRepository()
    success = repository.record_interaction(
        user_id=interaction.user_id,
        meal_id=interaction.meal_id,
        content_type=interaction.content_type,
        interaction_type=interaction.interaction_type
    )
    
    if not success:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to record interaction"
        )
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "status": "recorded",
        "execution_time_ms": round(execution_time, 2)
    }

@router.get("/user/{user_id}/history")
def get_user_meal_history(
    user_id: str,
    content_type: Optional[str] = None,
    limit: int = 10,
    db = Depends(get_db)
):
    """Get a user's meal interaction history."""
    start_time = time.time()
    
    # Validate content type if provided
    if content_type:
        content_type = validate_content_type(content_type)
    
    from data.repositories import InteractionRepository
    
    repository = InteractionRepository()
    history = repository.get_user_recent_interactions(
        user_id=user_id,
        content_type=content_type,
        limit=limit
    )
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "history": history,
        "count": len(history),
        "execution_time_ms": round(execution_time, 2)
    }

@router.get("/user/{user_id}/dietary-preferences")
def get_user_dietary_preferences(
    user_id: str,
    db = Depends(get_db)
):
    """Get a user's dietary preferences."""
    start_time = time.time()
    
    from data.repositories import InteractionRepository
    
    repository = InteractionRepository()
    preferences = repository.get_user_dietary_preferences(user_id)
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "dietary_preferences": preferences,
        "count": len(preferences),
        "execution_time_ms": round(execution_time, 2)
    }

@router.post("/user/{user_id}/dietary-preferences")
def set_user_dietary_preference(
    user_id: str,
    dietary_restriction_id: int,
    db = Depends(get_db)
):
    """Add a dietary preference for a user."""
    start_time = time.time()
    
    from data.repositories import InteractionRepository
    
    repository = InteractionRepository()
    success = repository.add_user_dietary_preference(
        user_id=user_id,
        dietary_restriction_id=dietary_restriction_id
    )
    
    if not success:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to add dietary preference"
        )
    
    execution_time = (time.time() - start_time) * 1000
    
    return {
        "status": "added",
        "execution_time_ms": round(execution_time, 2)
    }
////////////////////////////////////////////////////////////////////////////////

├── config
│   ├── __init__.py

////////////////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////////////////

│   └── settings.py

////////////////////////////////////////////////////////////////////////////////
"""
Configuration module for the meal recommendation service.
Exports all configuration values from settings.py.
"""
from config.settings import (
    # Database settings
    DATABASE_URL,
    
    # API settings
    API_HOST,
    API_PORT,
    RELOAD,
    
    # Embedding model settings
    EMBEDDING_MODEL,
    EMBEDDING_DIMENSION,
    
    # Recommendation settings
    DEFAULT_RECOMMENDATION_LIMIT,
    CONTENT_TYPES,
    ALLOWED_TRENDING_WINDOWS,
    INTERACTION_TYPES,
    
    # Scheduler settings
    EMBEDDING_GENERATION_INTERVAL,
    SCHEDULER_SLEEP_INTERVAL,
    
    # Client settings
    RECOMMENDATION_API_URL,
    
    # Cache settings
    ENABLE_CACHE,
    CACHE_EXPIRATION,
    
    # Meal-specific settings
    CUISINE_TYPES,
    DIETARY_RESTRICTIONS,
    
    # Similarity thresholds
    MIN_SIMILARITY_SCORE,
    MIN_COMMON_ITEMS,
    
    # Logging configuration
    LOG_LEVEL,
    LOG_FORMAT
)
////////////////////////////////////////////////////////////////////////////////

├── data
│   ├── __init__.py

////////////////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////////////////

│   ├── db.py

////////////////////////////////////////////////////////////////////////////////
"""
Database connection module.
Provides database connection pool and transaction management.
"""
from sqlalchemy import create_engine, text
from contextlib import contextmanager
from typing import Generator

from config.settings import DATABASE_URL

# Create database engine with connection pooling
engine = create_engine(DATABASE_URL, pool_size=10, max_overflow=20)

@contextmanager
def get_connection():
    """Get a database connection from the pool."""
    connection = engine.connect()
    try:
        yield connection
    finally:
        connection.close()

@contextmanager
def get_transaction():
    """Get a database connection with transaction."""
    connection = engine.connect()
    transaction = connection.begin()
    try:
        yield connection
        transaction.commit()
    except Exception:
        transaction.rollback()
        raise
    finally:
        connection.close()

def execute_query(query, params=None, is_transaction=False):
    """Execute a database query with parameters."""
    manager = get_transaction if is_transaction else get_connection
    
    with manager() as conn:
        result = conn.execute(text(query), params or {})
        return result

def test_connection():
    """Test the database connection."""
    try:
        with get_connection() as conn:
            result = conn.execute(text("SELECT 1"))
            print("Database connection successful!")
            return True
    except Exception as e:
        print(f"Database connection failed: {e}")
        return False
////////////////////////////////////////////////////////////////////////////////

│   ├── kaggle.py

////////////////////////////////////////////////////////////////////////////////
import kagglehub
import os

# Download the dataset
path = kagglehub.dataset_download("kriishukla/recipe-db")

# Access meals.csv
file_path = os.path.join(path, "meals.csv")

print("Dataset Path:", path)
print("Meals File Path:", file_path)

////////////////////////////////////////////////////////////////////////////////

│   ├── loader.py

////////////////////////////////////////////////////////////////////////////////
"""
Data loader for MealFlow recommendation system.
Imports datasets from CSV and JSON files into the PostgreSQL database.
"""
import os
import json
import pandas as pd
import logging
import time
from typing import Dict, List, Optional, Any
from dotenv import load_dotenv
from sqlalchemy import create_engine, text, Table, Column, Integer, String, Float, MetaData, inspect

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Get database connection string
DATABASE_URL = os.getenv("DATABASE_URL", "postgresql://postgres:postgres@localhost:5432/mealflow")

# Get data file paths
DATA_DIR = os.getenv("DATA_DIR", "data")
RECIPE_GENERAL_FILE = os.getenv("RECIPE_GENERAL_FILE", "RecipeDB_general.csv")
RECIPE_INGREDIENT_PHRASE_FILE = os.getenv("RECIPE_INGREDIENT_PHRASE_FILE", "RecipeDB_ingredient_phrase.csv")
RECIPE_INGREDIENT_FLAVOR_FILE = os.getenv("RECIPE_INGREDIENT_FLAVOR_FILE", "RecipeDB_ingredient_flavor.csv")
RECIPE_INSTRUCTIONS_FILE = os.getenv("RECIPE_INSTRUCTIONS_FILE", "RecipeDB_instructions.json")
MERGED_RECIPES_FILE = os.getenv("MERGED_RECIPES_FILE", "merged.csv")
BATCH_SIZE = int(os.getenv("BATCH_SIZE", 1000))

# Connect to database
engine = create_engine(DATABASE_URL)
metadata = MetaData()

def check_table_exists(table_name: str) -> bool:
    """Check if a table exists in the database."""
    inspector = inspect(engine)
    return table_name in inspector.get_table_names()

def create_tables():
    """Create all necessary tables if they don't exist."""
    logger.info("Creating tables if they don't exist...")

    # Recipe table
    if not check_table_exists("Recipe"):
        Recipe = Table(
            "Recipe", 
            metadata,
            Column("id", String, primary_key=True),
            Column("name", String),
            Column("cuisine", String),
            Column("prep_time", Integer),
            Column("cook_time", Integer),
            Column("total_time", Integer),
            Column("servings", Integer),
            Column("calories", Float),
            Column("ratings", Float),
            Column("url", String),
            Column("region", String),
            Column("sub_region", String),
            Column("continent", String),
            Column("source", String),
            Column("img_url", String),
            Column("carbohydrate", Float),
            Column("energy", Float),
            Column("protein", Float),
            Column("fat", Float),
            Column("utensils", String),
            Column("processes", String),
            Column("vegan", Float),
            Column("pescetarian", Float),
            Column("ovo_vegetarian", Float),
            Column("lacto_vegetarian", Float),
            Column("ovo_lacto_vegetarian", Float)
        )
        
    # Ingredient table
    if not check_table_exists("Ingredient"):
        Ingredient = Table(
            "Ingredient",
            metadata,
            Column("id", Integer, primary_key=True),
            Column("name", String, unique=True),
            Column("generic_name", String),
            Column("wiki_link", String),
            Column("wiki_image", String),
            Column("flavordb_category", String),
            Column("dietrx_category", String),
            Column("flavor_db_link", String),
            Column("flavordb_id", Integer),
            Column("diet_rx_link", String)
        )

    # RecipeIngredient table
    if not check_table_exists("RecipeIngredient"):
        RecipeIngredient = Table(
            "RecipeIngredient",
            metadata,
            Column("id", Integer, primary_key=True),
            Column("recipe_id", String),
            Column("ingredient_id", Integer),
            Column("quantity", String),
            Column("unit", String),
            Column("preparation_method", String)
        )

    # Merged table
    if not check_table_exists("MergedRecipes"):
        MergedRecipes = Table(
            "MergedRecipes",
            metadata,
            Column("recipe_id", String, primary_key=True),
            Column("recipe_name", String),
            Column("cuisine", String),
            Column("prep_time", Integer),
            Column("cook_time", Integer),
            Column("total_time", Integer),
            Column("servings", Integer),
            Column("calories", Float),
            Column("ratings", Float),
            Column("ingredient_count", Integer),
            Column("complexity_score", Integer),
            Column("dietary_flags", String)
        )
        
    # Recipe Instructions table
    if not check_table_exists("RecipeInstruction"):
        RecipeInstruction = Table(
            "RecipeInstruction",
            metadata,
            Column("id", Integer, primary_key=True),
            Column("recipe_id", String),
            Column("step_number", Integer),
            Column("instruction", String)
        )

    # Cuisine table if not already created
    if not check_table_exists("Cuisine"):
        Cuisine = Table(
            "Cuisine",
            metadata,
            Column("id", Integer, primary_key=True),
            Column("name", String, unique=True)
        )

    # Create all tables
    metadata.create_all(engine)
    logger.info("Tables created successfully")

def clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """Clean a dataframe by stripping whitespace, removing quotes, handling NaN values."""
    # Replace missing values with None
    df = df.where(pd.notnull(df), None)
    
    # Strip whitespace from string columns
    for col in df.select_dtypes(include=['object']).columns:
        if df[col].dtype == 'object':
            df[col] = df[col].str.strip() if df[col].dtype == 'object' else df[col]
            
            # Remove quotes from string columns
            df[col] = df[col].str.replace('"', '') if df[col].dtype == 'object' else df[col]
            
    return df

def load_recipe_general():
    """Load recipe general data from CSV."""
    file_path = os.path.join(DATA_DIR, RECIPE_GENERAL_FILE)
    logger.info(f"Loading recipe general data from {file_path}")
    
    if not os.path.exists(file_path):
        logger.error(f"File not found: {file_path}")
        return
    
    try:
        # Read the CSV file
        df = pd.read_csv(file_path)
        df = clean_dataframe(df)
        
        # Rename column to match our schema
        df = df.rename(columns={
            'Recipe_id': 'id',
            'Recipe_title': 'name'
        })
        
        # Insert data into database in batches
        with engine.begin() as conn:
            for i in range(0, len(df), BATCH_SIZE):
                batch = df.iloc[i:i+BATCH_SIZE]
                batch.to_sql('Recipe', conn, if_exists='append', index=False, 
                            method='multi', chunksize=BATCH_SIZE)
                logger.info(f"Inserted batch {i//BATCH_SIZE + 1} of {(len(df)//BATCH_SIZE) + 1} into Recipe table")
        
        logger.info(f"Loaded {len(df)} recipes into Recipe table")
        
    except Exception as e:
        logger.error(f"Error loading recipe general data: {e}")

def load_ingredients():
    """Load ingredient data from CSV."""
    file_path = os.path.join(DATA_DIR, RECIPE_INGREDIENT_FLAVOR_FILE)
    logger.info(f"Loading ingredient data from {file_path}")
    
    if not os.path.exists(file_path):
        logger.error(f"File not found: {file_path}")
        return
    
    try:
        # Read the CSV file
        df = pd.read_csv(file_path)
        df = clean_dataframe(df)
        
        # Rename columns to match our schema
        df = df.rename(columns={
            'IngID': 'id',
            'ingredient': 'name',
            'generic_name': 'generic_name',
            'wikilink': 'wiki_link',
            'wikiimage': 'wiki_image',
            'FlavorDB_Category': 'flavordb_category',
            'Dietrx_Category': 'dietrx_category',
            'Flavor_DB_Link': 'flavor_db_link',
            'flavordb_id': 'flavordb_id',
            'Diet_rx_link': 'diet_rx_link'
        })
        
        # Insert data into database in batches
        with engine.begin() as conn:
            for i in range(0, len(df), BATCH_SIZE):
                batch = df.iloc[i:i+BATCH_SIZE]
                batch.to_sql('Ingredient', conn, if_exists='append', index=False,
                            method='multi', chunksize=BATCH_SIZE)
                logger.info(f"Inserted batch {i//BATCH_SIZE + 1} of {(len(df)//BATCH_SIZE) + 1} into Ingredient table")
        
        logger.info(f"Loaded {len(df)} ingredients into Ingredient table")
        
    except Exception as e:
        logger.error(f"Error loading ingredient data: {e}")

def load_recipe_ingredients():
    """Load recipe ingredient relationships from CSV."""
    file_path = os.path.join(DATA_DIR, RECIPE_INGREDIENT_PHRASE_FILE)
    logger.info(f"Loading recipe ingredient data from {file_path}")
    
    if not os.path.exists(file_path):
        logger.error(f"File not found: {file_path}")
        return
    
    try:
        # Read the CSV file
        df = pd.read_csv(file_path)
        df = clean_dataframe(df)
        
        # Rename columns to match our schema
        df = df.rename(columns={
            'recipe_no': 'recipe_id',
            'ing_id': 'ingredient_id',
            'state': 'preparation_method'
        })
        
        # Select relevant columns
        df = df[['recipe_id', 'ingredient_id', 'quantity', 'unit', 'preparation_method']]
        
        # Insert data into database in batches
        with engine.begin() as conn:
            for i in range(0, len(df), BATCH_SIZE):
                batch = df.iloc[i:i+BATCH_SIZE]
                batch.to_sql('RecipeIngredient', conn, if_exists='append', index=True,
                            method='multi', chunksize=BATCH_SIZE)
                logger.info(f"Inserted batch {i//BATCH_SIZE + 1} of {(len(df)//BATCH_SIZE) + 1} into RecipeIngredient table")
        
        logger.info(f"Loaded {len(df)} recipe-ingredient relationships into RecipeIngredient table")
        
    except Exception as e:
        logger.error(f"Error loading recipe ingredient data: {e}")

def load_merged_recipes():
    """Load merged recipe data from CSV."""
    file_path = os.path.join(DATA_DIR, MERGED_RECIPES_FILE)
    logger.info(f"Loading merged recipe data from {file_path}")
    
    if not os.path.exists(file_path):
        logger.error(f"File not found: {file_path}")
        return
    
    try:
        # Read the CSV file
        df = pd.read_csv(file_path)
        df = clean_dataframe(df)
        
        # Insert data into database in batches
        with engine.begin() as conn:
            for i in range(0, len(df), BATCH_SIZE):
                batch = df.iloc[i:i+BATCH_SIZE]
                batch.to_sql('MergedRecipes', conn, if_exists='append', index=False,
                            method='multi', chunksize=BATCH_SIZE)
                logger.info(f"Inserted batch {i//BATCH_SIZE + 1} of {(len(df)//BATCH_SIZE) + 1} into MergedRecipes table")
        
        logger.info(f"Loaded {len(df)} merged recipes into MergedRecipes table")
        
    except Exception as e:
        logger.error(f"Error loading merged recipe data: {e}")

def load_recipe_instructions():
    """Load recipe instructions from JSON file."""
    file_path = os.path.join(DATA_DIR, RECIPE_INSTRUCTIONS_FILE)
    logger.info(f"Loading recipe instructions from {file_path}")
    
    if not os.path.exists(file_path):
        logger.error(f"File not found: {file_path}")
        return
    
    try:
        # Read the JSON file
        with open(file_path, 'r') as f:
            data = json.load(f)
        
        # Extract instructions
        instructions = []
        for recipe in data.get('recipes', []):
            recipe_id = recipe.get('recipe_id')
            for step in recipe.get('steps', []):
                instructions.append({
                    'recipe_id': recipe_id,
                    'step_number': step.get('step_number'),
                    'instruction': step.get('instruction')
                })
        
        # Convert to dataframe
        df = pd.DataFrame(instructions)
        
        # Insert data into database in batches
        with engine.begin() as conn:
            for i in range(0, len(df), BATCH_SIZE):
                batch = df.iloc[i:i+BATCH_SIZE]
                batch.to_sql('RecipeInstruction', conn, if_exists='append', index=True,
                            method='multi', chunksize=BATCH_SIZE)
                logger.info(f"Inserted batch {i//BATCH_SIZE + 1} of {(len(df)//BATCH_SIZE) + 1} into RecipeInstruction table")
        
        logger.info(f"Loaded {len(df)} recipe instructions into RecipeInstruction table")
        
    except Exception as e:
        logger.error(f"Error loading recipe instructions: {e}")

def populate_cuisines():
    """Extract and populate unique cuisines from recipe data."""
    logger.info("Populating cuisines from recipe data")
    
    try:
        # Extract unique cuisines from Recipe table
        query = text("""
            INSERT INTO "Cuisine" (name)
            SELECT DISTINCT cuisine FROM "Recipe" WHERE cuisine IS NOT NULL
            ON CONFLICT (name) DO NOTHING
        """)
        
        with engine.begin() as conn:
            conn.execute(query)
        
        # Count the number of cuisines
        query = text('SELECT COUNT(*) FROM "Cuisine"')
        with engine.connect() as conn:
            count = conn.execute(query).scalar()
        
        logger.info(f"Populated {count} cuisines into Cuisine table")
        
    except Exception as e:
        logger.error(f"Error populating cuisines: {e}")

def update_foreign_keys():
    """Update foreign key references in tables."""
    logger.info("Updating foreign key references")
    
    try:
        # Add cuisine_id to Recipe table
        if not check_column_exists("Recipe", "cuisine_id"):
            query = text("""
                ALTER TABLE "Recipe" ADD COLUMN cuisine_id INTEGER;
                UPDATE "Recipe" r
                SET cuisine_id = c.id
                FROM "Cuisine" c
                WHERE r.cuisine = c.name;
            """)
            
            with engine.begin() as conn:
                conn.execute(query)
            
            logger.info("Added and updated cuisine_id in Recipe table")
        
    except Exception as e:
        logger.error(f"Error updating foreign keys: {e}")

def check_column_exists(table_name: str, column_name: str) -> bool:
    """Check if a column exists in a table."""
    inspector = inspect(engine)
    columns = [c['name'] for c in inspector.get_columns(table_name)]
    return column_name in columns

def main():
    """Main execution function."""
    start_time = time.time()
    logger.info("Starting data import...")
    
    # Create tables
    create_tables()
    
    # Load data
    load_recipe_general()
    load_ingredients()
    load_recipe_ingredients()
    load_merged_recipes()
    load_recipe_instructions()
    
    # Post-processing
    populate_cuisines()
    update_foreign_keys()
    
    elapsed_time = time.time() - start_time
    logger.info(f"Data import completed in {elapsed_time:.2f} seconds")

if __name__ == "__main__":
    main()
////////////////////////////////////////////////////////////////////////////////

│   ├── query.py

////////////////////////////////////////////////////////////////////////////////
"""
SQL Queries for the meal recommendation service.
Optimized for production use with improved indexing and query performance.
"""
from config import EMBEDDING_DIMENSION

#######################
# SETUP QUERIES       #
#######################

# Query to enable pgvector extension
ENABLE_PGVECTOR = """
CREATE EXTENSION IF NOT EXISTS vector
"""

# Query to create meal embeddings table with optimized index
CREATE_CONTENT_EMBEDDINGS_TABLE = """
CREATE TABLE IF NOT EXISTS content_embeddings (
    id SERIAL PRIMARY KEY,
    meal_id TEXT NOT NULL,
    content_type TEXT NOT NULL,  -- 'meal' or 'recipe'
    embedding vector({embedding_dimension}),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(meal_id, content_type)
)
"""

# Create optimized index for vector search with IVFFlat indexing
# This offers better performance for larger databases compared to simple index
CREATE_EMBEDDINGS_INDEX = """
CREATE INDEX IF NOT EXISTS content_embeddings_vector_idx 
ON content_embeddings USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);

CREATE INDEX IF NOT EXISTS content_embeddings_content_type_idx
ON content_embeddings (content_type);

CREATE INDEX IF NOT EXISTS content_embeddings_meal_id_idx
ON content_embeddings (meal_id);
"""

# Optimized interactions table with partitioning hints for high-volume data
CREATE_INTERACTIONS_TABLE = """
CREATE TABLE IF NOT EXISTS recommendation_interactions (
    id SERIAL PRIMARY KEY,
    user_id TEXT NOT NULL,
    meal_id TEXT NOT NULL,
    content_type TEXT NOT NULL,  -- 'meal', 'recipe'
    interaction_type TEXT NOT NULL,  -- 'view', 'like', 'save', 'cook'
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
)
"""

# Create optimized indexes for interactions
CREATE_INTERACTIONS_INDEXES = """
-- Index for user lookups (most common query pattern)
CREATE INDEX IF NOT EXISTS rec_interactions_user_idx ON recommendation_interactions(user_id);

-- Composite index for meal+content lookups
CREATE INDEX IF NOT EXISTS rec_interactions_meal_content_idx 
ON recommendation_interactions(meal_id, content_type);

-- Index for filtering by interaction type
CREATE INDEX IF NOT EXISTS rec_interactions_type_idx ON recommendation_interactions(interaction_type);

-- Index for time-based queries with BRIN for better performance on timestamp data
CREATE INDEX IF NOT EXISTS rec_interactions_created_brin_idx 
ON recommendation_interactions USING BRIN (created_at);

-- Composite index for user history queries
CREATE INDEX IF NOT EXISTS rec_interactions_user_created_idx
ON recommendation_interactions(user_id, created_at DESC);

-- Composite index for trending content queries
CREATE INDEX IF NOT EXISTS rec_interactions_content_created_idx
ON recommendation_interactions(content_type, created_at DESC);
"""

# Query to create cuisine reference table
CREATE_CUISINE_TABLE = """
CREATE TABLE IF NOT EXISTS "Cuisine" (
    id SERIAL PRIMARY KEY,
    name TEXT NOT NULL UNIQUE
)
"""

# Query to create dietary restriction reference table
CREATE_DIETARY_RESTRICTION_TABLE = """
CREATE TABLE IF NOT EXISTS "DietaryRestriction" (
    id SERIAL PRIMARY KEY,
    name TEXT NOT NULL UNIQUE
)
"""

# Query to create user dietary preferences table
CREATE_USER_DIETARY_PREFERENCE_TABLE = """
CREATE TABLE IF NOT EXISTS "UserDietaryPreference" (
    id SERIAL PRIMARY KEY,
    user_id TEXT NOT NULL,
    dietary_restriction_id INTEGER NOT NULL REFERENCES "DietaryRestriction"(id),
    UNIQUE(user_id, dietary_restriction_id)
);

CREATE INDEX IF NOT EXISTS user_dietary_pref_user_idx
ON "UserDietaryPreference"(user_id);
"""

# Query to create meal dietary restrictions table
CREATE_MEAL_DIETARY_RESTRICTION_TABLE = """
CREATE TABLE IF NOT EXISTS "MealDietaryRestriction" (
    id SERIAL PRIMARY KEY,
    meal_id TEXT NOT NULL,
    dietary_restriction_id INTEGER NOT NULL REFERENCES "DietaryRestriction"(id),
    UNIQUE(meal_id, dietary_restriction_id)
);

CREATE INDEX IF NOT EXISTS meal_dietary_meal_idx
ON "MealDietaryRestriction"(meal_id);

CREATE INDEX IF NOT EXISTS meal_dietary_restriction_idx
ON "MealDietaryRestriction"(dietary_restriction_id);
"""

# Query to create ingredients table
CREATE_INGREDIENT_TABLE = """
CREATE TABLE IF NOT EXISTS "Ingredient" (
    id SERIAL PRIMARY KEY,
    name TEXT NOT NULL UNIQUE
);

CREATE INDEX IF NOT EXISTS ingredient_name_idx
ON "Ingredient" USING gin(name gin_trgm_ops);
"""

# Query to create meal ingredients table
CREATE_MEAL_INGREDIENT_TABLE = """
CREATE TABLE IF NOT EXISTS "MealIngredient" (
    id SERIAL PRIMARY KEY,
    meal_id TEXT NOT NULL,
    ingredient_id INTEGER NOT NULL REFERENCES "Ingredient"(id),
    amount TEXT,
    UNIQUE(meal_id, ingredient_id)
);

CREATE INDEX IF NOT EXISTS meal_ingredient_meal_idx
ON "MealIngredient"(meal_id);

CREATE INDEX IF NOT EXISTS meal_ingredient_ingredient_idx
ON "MealIngredient"(ingredient_id);
"""

# Query to enable trigram indexing for text search
ENABLE_TRIGRAM = """
CREATE EXTENSION IF NOT EXISTS pg_trgm
"""

# Query to insert default cuisines
INSERT_DEFAULT_CUISINES = """
INSERT INTO "Cuisine" (name) VALUES
('italian'), ('mexican'), ('chinese'), ('indian'), ('american'),
('french'), ('japanese'), ('mediterranean'), ('thai'), ('other'),
('middle eastern'), ('korean'), ('vietnamese'), ('spanish'), ('greek'),
('caribbean'), ('brazilian'), ('german'), ('british'), ('african')
ON CONFLICT (name) DO NOTHING
"""

# Query to insert default dietary restrictions
INSERT_DEFAULT_DIETARY_RESTRICTIONS = """
INSERT INTO "DietaryRestriction" (name) VALUES
('vegetarian'), ('vegan'), ('gluten-free'), ('dairy-free'),
('keto'), ('paleo'), ('low-carb'), ('low-fat'), ('pescatarian'),
('nut-free'), ('egg-free'), ('soy-free'), ('halal'), ('kosher')
ON CONFLICT (name) DO NOTHING
"""

#######################
# EMBEDDING QUERIES   #
#######################

# Query to save or update a meal embedding with optimized upsert
SAVE_EMBEDDING = """
INSERT INTO content_embeddings (meal_id, content_type, embedding)
VALUES (:meal_id, :content_type, :embedding)
ON CONFLICT (meal_id, content_type) 
DO UPDATE SET 
    embedding = :embedding, 
    updated_at = CURRENT_TIMESTAMP
"""

# Query to get the embedding for specific meal
GET_EMBEDDING = """
SELECT embedding
FROM content_embeddings
WHERE meal_id = :meal_id AND content_type = :content_type
"""

# Base query for finding similar meals (optimized with CTE)
FIND_SIMILAR_CONTENT_BASE = """
WITH candidate_embeddings AS (
    SELECT ce.meal_id, ce.content_type,
           CASE WHEN ce.content_type = 'meal' THEN m.title
                WHEN ce.content_type = 'recipe' THEN r.name
           END as title,
           1 - (ce.embedding <=> :embedding) AS similarity
    FROM content_embeddings ce
    LEFT JOIN "Meal" m ON ce.meal_id = m.id AND ce.content_type = 'meal'
    LEFT JOIN "Recipe" r ON ce.meal_id = r.id AND ce.content_type = 'recipe'
    WHERE 1=1
    {type_filter}
    {exclude_clause}
    ORDER BY similarity DESC
    LIMIT :limit * 2
)
SELECT meal_id, content_type, title, similarity
FROM candidate_embeddings
WHERE similarity > 0.5
ORDER BY similarity DESC
LIMIT :limit
"""

# Query to get meals that don't have embeddings yet (optimized with limit)
GET_MEALS_WITHOUT_EMBEDDINGS = """
SELECT m.id, m.title, m.description
FROM "Meal" m
LEFT JOIN content_embeddings ce ON ce.meal_id = m.id AND ce.content_type = 'meal'
WHERE ce.id IS NULL
LIMIT :limit
"""

# Query to get recipes that don't have embeddings yet (optimized with limit)
GET_RECIPES_WITHOUT_EMBEDDINGS = """
SELECT r.id, r.name, r.instructions
FROM "Recipe" r
LEFT JOIN content_embeddings ce ON ce.meal_id = r.id AND ce.content_type = 'recipe'
WHERE ce.id IS NULL
LIMIT :limit
"""

# Query to find meals by cuisine for embedding
FIND_MEALS_BY_CUISINE_FOR_EMBEDDING = """
SELECT m.id, m.title, m.description
FROM "Meal" m
WHERE m.cuisine_id = :cuisine_id
AND m.id NOT IN (
    SELECT meal_id FROM content_embeddings WHERE content_type = 'meal'
)
LIMIT :limit
"""

# Query to get total counts of items without embeddings
GET_EMBEDDING_STATS = """
SELECT 
    (SELECT COUNT(*) FROM "Meal" m 
     LEFT JOIN content_embeddings ce ON ce.meal_id = m.id AND ce.content_type = 'meal' 
     WHERE ce.id IS NULL) as meals_without_embeddings,
     
    (SELECT COUNT(*) FROM "Recipe" r 
     LEFT JOIN content_embeddings ce ON ce.meal_id = r.id AND ce.content_type = 'recipe' 
     WHERE ce.id IS NULL) as recipes_without_embeddings,
     
    (SELECT COUNT(*) FROM content_embeddings) as total_embeddings
"""

#######################
# INTERACTION QUERIES #
#######################

# Query to record a user interaction with a meal
RECORD_INTERACTION = """
INSERT INTO recommendation_interactions
(user_id, meal_id, content_type, interaction_type)
VALUES (:user_id, :meal_id, :content_type, :interaction_type)
"""

# Query to get recent interactions for a user (optimized with index hint)
GET_USER_RECENT_INTERACTIONS_BASE = """
/*+ INDEX(recommendation_interactions rec_interactions_user_created_idx) */
SELECT meal_id, content_type, interaction_type, created_at
FROM recommendation_interactions
WHERE user_id = :user_id
{type_filter}
ORDER BY created_at DESC
LIMIT :limit
"""

# Base query for getting trending meals (optimized with window function)
GET_TRENDING_MEALS_BASE = """
WITH trending AS (
    SELECT ri.meal_id, ri.content_type,
           CASE WHEN ri.content_type = 'meal' THEN m.title
                WHEN ri.content_type = 'recipe' THEN r.name
           END as title,
           COUNT(*) as popularity,
           ROW_NUMBER() OVER (PARTITION BY ri.content_type ORDER BY COUNT(*) DESC) as rank
    FROM recommendation_interactions ri
    LEFT JOIN "Meal" m ON ri.meal_id = m.id AND ri.content_type = 'meal'
    LEFT JOIN "Recipe" r ON ri.meal_id = r.id AND ri.content_type = 'recipe'
    WHERE ri.created_at > {time_clause}
    {type_filter}
    GROUP BY ri.meal_id, ri.content_type, m.title, r.name
)
SELECT meal_id, content_type, title, popularity
FROM trending
WHERE rank <= :limit
ORDER BY popularity DESC
"""

# Query to find users with similar meal preferences (optimized with CTE)
FIND_SIMILAR_USERS = """
WITH user_items AS (
    SELECT meal_id, content_type
    FROM recommendation_interactions
    WHERE user_id = :user_id
),
similar_users AS (
    SELECT ri.user_id,
           COUNT(DISTINCT ri.meal_id) as common_items,
           ROW_NUMBER() OVER (ORDER BY COUNT(DISTINCT ri.meal_id) DESC) as rank
    FROM recommendation_interactions ri
    JOIN user_items ui ON ri.meal_id = ui.meal_id AND ri.content_type = ui.content_type
    WHERE ri.user_id != :user_id
    GROUP BY ri.user_id
    HAVING COUNT(DISTINCT ri.meal_id) > :min_common_items
)
SELECT user_id
FROM similar_users
WHERE rank <= :limit
"""

# Base query for getting meals from similar users (optimized with NOT EXISTS)
GET_MEALS_FROM_SIMILAR_USERS_BASE = """
WITH user_recommendations AS (
    SELECT ri.meal_id, ri.content_type, COUNT(*) as interaction_count,
           CASE WHEN ri.content_type = 'meal' THEN m.title
                WHEN ri.content_type = 'recipe' THEN r.name
           END as title,
           ROW_NUMBER() OVER (ORDER BY COUNT(*) DESC) as rank
    FROM recommendation_interactions ri
    LEFT JOIN "Meal" m ON ri.meal_id = m.id AND ri.content_type = 'meal'
    LEFT JOIN "Recipe" r ON ri.meal_id = r.id AND ri.content_type = 'recipe'
    WHERE ri.user_id IN ({user_placeholders})
    AND NOT EXISTS (
        SELECT 1 
        FROM recommendation_interactions ri2
        WHERE ri2.user_id = :user_id
        AND ri2.meal_id = ri.meal_id
        AND ri2.content_type = ri.content_type
    )
    {type_filter}
    GROUP BY ri.meal_id, ri.content_type, m.title, r.name
)
SELECT meal_id, content_type, interaction_count, title
FROM user_recommendations
WHERE rank <= :limit
"""

# Query to get user interaction statistics
GET_USER_INTERACTION_STATS = """
SELECT 
    interaction_type,
    COUNT(*) as count,
    MAX(created_at) as latest
FROM recommendation_interactions
WHERE user_id = :user_id
GROUP BY interaction_type
ORDER BY count DESC
"""

# Query to get interaction stats by content type
GET_CONTENT_TYPE_STATS = """
SELECT 
    content_type,
    COUNT(*) as interaction_count,
    COUNT(DISTINCT meal_id) as unique_items,
    COUNT(DISTINCT user_id) as unique_users
FROM recommendation_interactions
GROUP BY content_type
"""

#######################
# RECOMMENDATION QUERIES #
#######################

# Query for finding similar meals based on co-occurrence patterns (optimized with window function)
FIND_SIMILAR_ITEMS = """
WITH users_who_interacted AS (
    SELECT DISTINCT user_id
    FROM recommendation_interactions
    WHERE meal_id = :meal_id
),
similar_items AS (
    SELECT ri2.meal_id, ri2.content_type,
           CASE WHEN ri2.content_type = 'meal' THEN m.title
                WHEN ri2.content_type = 'recipe' THEN r.name
           END as title,
           COUNT(DISTINCT ri2.user_id) as co_occurrence_count,
           ROW_NUMBER() OVER (ORDER BY COUNT(DISTINCT ri2.user_id) DESC) as rank
    FROM recommendation_interactions ri2
    JOIN users_who_interacted uwi ON ri2.user_id = uwi.user_id
    LEFT JOIN "Meal" m ON ri2.meal_id = m.id AND ri2.content_type = 'meal'
    LEFT JOIN "Recipe" r ON ri2.meal_id = r.id AND ri2.content_type = 'recipe'
    WHERE ri2.meal_id != :meal_id
    {type_filter}
    GROUP BY ri2.meal_id, ri2.content_type, m.title, r.name
)
SELECT meal_id, content_type, title, co_occurrence_count
FROM similar_items
WHERE rank <= :limit
"""

# Query for finding meals with similar ingredients (optimized with CTE and Jaccard similarity)
FIND_MEALS_WITH_SIMILAR_INGREDIENTS = """
WITH meal_ingredients AS (
    SELECT ingredient_id
    FROM "MealIngredient"
    WHERE meal_id = :meal_id
),
source_count AS (
    SELECT COUNT(*) AS count
    FROM meal_ingredients
),
ingredient_counts AS (
    SELECT 
        m.id, 
        m.title, 
        COUNT(mi.ingredient_id) AS common_ingredients,
        (SELECT count FROM source_count) AS source_ingredient_count,
        COUNT(mi.ingredient_id)::float / 
        ((SELECT count FROM source_count) + 
         (SELECT COUNT(*) FROM "MealIngredient" WHERE meal_id = m.id) - 
         COUNT(mi.ingredient_id))::float AS jaccard_similarity
    FROM "Meal" m
    JOIN "MealIngredient" mi ON m.id = mi.meal_id
    JOIN meal_ingredients src ON mi.ingredient_id = src.ingredient_id
    WHERE m.id != :meal_id
    GROUP BY m.id, m.title
)
SELECT 
    id, 
    title, 
    common_ingredients,
    jaccard_similarity AS similarity_score
FROM ingredient_counts
ORDER BY jaccard_similarity DESC, common_ingredients DESC
LIMIT :limit
"""

# Query for getting meals by cuisine (with improved joining)
GET_CUISINE_MEALS = """
SELECT m.id, m.title
FROM "Meal" m
JOIN "Cuisine" c ON m.cuisine_id = c.id
WHERE c.id = :cuisine_id
ORDER BY m.ratings DESC NULLS LAST
LIMIT :limit
"""

# Query for getting meals by dietary preference (optimized with direct join)
GET_DIETARY_PREFERENCE_MEALS = """
SELECT m.id, m.title
FROM "Meal" m
JOIN "MealDietaryRestriction" mdr ON m.id = mdr.meal_id
WHERE mdr.dietary_restriction_id = :dietary_restriction_id
ORDER BY m.ratings DESC NULLS LAST
LIMIT :limit
"""

# Query for getting a user's dietary preferences
GET_USER_DIETARY_PREFERENCES = """
SELECT dr.id, dr.name
FROM "UserDietaryPreference" udp
JOIN "DietaryRestriction" dr ON udp.dietary_restriction_id = dr.id
WHERE udp.user_id = :user_id
"""

# Query for getting similar meals based on ingredients (with normalized similarity score)
GET_SIMILAR_MEALS_BY_INGREDIENTS = """
WITH meal_ingredients AS (
    SELECT ingredient_id
    FROM "MealIngredient"
    WHERE meal_id = :meal_id
),
similarity_scores AS (
    SELECT 
        m1.id, 
        m1.title, 
        COUNT(mi1.ingredient_id) as ingredient_match_count,
        COUNT(mi1.ingredient_id)::float / 
        (SELECT COUNT(*) FROM "MealIngredient" WHERE meal_id = :meal_id)::float as similarity
    FROM "Meal" m1
    JOIN "MealIngredient" mi1 ON m1.id = mi1.meal_id
    JOIN meal_ingredients mi2 ON mi1.ingredient_id = mi2.ingredient_id
    WHERE m1.id != :meal_id
    GROUP BY m1.id, m1.title
)
SELECT id, title, ingredient_match_count, similarity
FROM similarity_scores
WHERE similarity > 0.2
ORDER BY similarity DESC, ingredient_match_count DESC
LIMIT :limit
"""

# Query for getting meal ingredients
GET_MEAL_INGREDIENTS = """
SELECT i.id, i.name, mi.amount
FROM "MealIngredient" mi
JOIN "Ingredient" i ON mi.ingredient_id = i.id
WHERE mi.meal_id = :meal_id
"""

# Query for getting recipe ingredients
GET_RECIPE_INGREDIENTS = """
SELECT i.id, i.name, ri.amount
FROM "RecipeIngredient" ri
JOIN "Ingredient" i ON ri.ingredient_id = i.id
WHERE ri.recipe_id = :recipe_id
"""

# Query for getting personalized meal recommendations based on dietary preferences (optimized)
GET_MEALS_BY_USER_DIETARY_PREFERENCES = """
WITH user_restrictions AS (
    SELECT dietary_restriction_id
    FROM "UserDietaryPreference"
    WHERE user_id = :user_id
),
eligible_meals AS (
    SELECT 
        m.id, 
        m.title, 
        m.description,
        COUNT(DISTINCT mdr.dietary_restriction_id) as matching_restrictions,
        ROW_NUMBER() OVER (ORDER BY COUNT(DISTINCT mdr.dietary_restriction_id) DESC, RANDOM()) as rank
    FROM "Meal" m
    JOIN "MealDietaryRestriction" mdr ON m.id = mdr.meal_id
    JOIN user_restrictions ur ON mdr.dietary_restriction_id = ur.dietary_restriction_id
    GROUP BY m.id, m.title, m.description
)
SELECT id, title, description
FROM eligible_meals
WHERE rank <= :limit
"""

# Query for getting meals with high popularity (optimized with window function)
GET_POPULAR_MEALS = """
WITH popular AS (
    SELECT 
        m.id, 
        m.title, 
        COUNT(ri.id) as popularity,
        ROW_NUMBER() OVER (ORDER BY COUNT(ri.id) DESC) as rank
    FROM "Meal" m
    JOIN recommendation_interactions ri ON m.id = ri.meal_id AND ri.content_type = 'meal'
    WHERE ri.created_at > NOW() - INTERVAL :time_window
    GROUP BY m.id, m.title
    HAVING COUNT(ri.id) > :min_interactions
)
SELECT id, title, popularity
FROM popular
WHERE rank <= :limit
"""

# Query for getting meals by time of day (optimized with user preferences)
GET_MEALS_BY_TIME_OF_DAY = """
WITH user_preferred_cuisines AS (
    SELECT m.cuisine_id, COUNT(*) as interaction_count
    FROM recommendation_interactions ri
    JOIN "Meal" m ON ri.meal_id = m.id AND ri.content_type = 'meal'
    WHERE ri.user_id = :user_id
    GROUP BY m.cuisine_id
    ORDER BY interaction_count DESC
    LIMIT 3
),
meals_by_type AS (
    SELECT 
        m.id, 
        m.title, 
        m.description,
        CASE 
            WHEN m.cuisine_id IN (SELECT cuisine_id FROM user_preferred_cuisines) THEN 0
            ELSE 1
        END as preference_rank,
        ROW_NUMBER() OVER (
            PARTITION BY (CASE WHEN m.cuisine_id IN (SELECT cuisine_id FROM user_preferred_cuisines) THEN 0 ELSE 1 END)
            ORDER BY RANDOM()
        ) as rand_rank
    FROM "Meal" m
    WHERE m.meal_type = :meal_type
)
SELECT id, title, description
FROM meals_by_type
ORDER BY preference_rank, rand_rank
LIMIT :limit
"""

# Query for getting low-carb or low-calorie meals (optimized)
GET_HEALTHY_MEALS = """
WITH healthy_meals AS (
    SELECT 
        m.id, 
        m.title, 
        m.calories,
        CASE 
            WHEN m.id IN (
                SELECT meal_id FROM "MealDietaryRestriction" 
                WHERE dietary_restriction_id IN (
                    SELECT id FROM "DietaryRestriction" WHERE name IN ('low-carb', 'keto')
                )
            ) THEN 0
            ELSE 1
        END as diet_rank,
        ROW_NUMBER() OVER (
            PARTITION BY (CASE 
                WHEN m.id IN (
                    SELECT meal_id FROM "MealDietaryRestriction" 
                    WHERE dietary_restriction_id IN (
                        SELECT id FROM "DietaryRestriction" WHERE name IN ('low-carb', 'keto')
                    )
                ) THEN 0
                ELSE 1
            END)
            ORDER BY COALESCE(m.calories, 9999)
        ) as calorie_rank
    FROM "Meal" m
    WHERE 
        (m.calories IS NULL OR m.calories < :max_calories)
        AND (:low_carb = FALSE OR m.id IN (
            SELECT meal_id FROM "MealDietaryRestriction" 
            WHERE dietary_restriction_id IN (
                SELECT id FROM "DietaryRestriction" WHERE name IN ('low-carb', 'keto')
            )
        ))
)
SELECT id, title, calories
FROM healthy_meals
ORDER BY diet_rank, calorie_rank
LIMIT :limit
"""

# Query for finding meals suitable for meal planning (optimized with CTEs)
GET_MEAL_PLAN_RECOMMENDATIONS = """
WITH user_favorite_cuisines AS (
    SELECT m.cuisine_id, COUNT(*) as interaction_count
    FROM recommendation_interactions ri
    JOIN "Meal" m ON ri.meal_id = m.id AND ri.content_type = 'meal'
    WHERE ri.user_id = :user_id
    GROUP BY m.cuisine_id
    ORDER BY interaction_count DESC
    LIMIT 3
),
user_diet_restrictions AS (
    SELECT dietary_restriction_id
    FROM "UserDietaryPreference"
    WHERE user_id = :user_id
),
eligible_meals AS (
    SELECT 
        m.id, 
        m.title, 
        m.meal_type, 
        m.prep_time, 
        m.cuisine_id,
        CASE 
            WHEN EXISTS (
                SELECT 1 
                FROM "MealDietaryRestriction" mdr
                JOIN user_diet_restrictions udr ON mdr.dietary_restriction_id = udr.dietary_restriction_id
                WHERE mdr.meal_id = m.id
            ) THEN 0
            ELSE 1
        END as diet_match,
        CASE 
            WHEN m.cuisine_id IN (SELECT cuisine_id FROM user_favorite_cuisines) THEN 0
            ELSE 1
        END as cuisine_match,
        ROW_NUMBER() OVER (
            PARTITION BY CASE 
                WHEN EXISTS (
                    SELECT 1 
                    FROM "MealDietaryRestriction" mdr
                    JOIN user_diet_restrictions udr ON mdr.dietary_restriction_id = udr.dietary_restriction_id
                    WHERE mdr.meal_id = m.id
                ) THEN 0
                ELSE 1
            END,
            CASE 
                WHEN m.cuisine_id IN (SELECT cuisine_id FROM user_favorite_cuisines) THEN 0
                ELSE 1
            END
            ORDER BY RANDOM()
        ) as rank
    FROM "Meal" m
    WHERE 
        (m.meal_type = :meal_type OR :meal_type IS NULL)
        AND (m.cuisine_id IN (SELECT cuisine_id FROM user_favorite_cuisines) OR :ignore_cuisine = TRUE)
        AND (EXISTS (
            SELECT 1 
            FROM "MealDietaryRestriction" mdr
            JOIN user_diet_restrictions udr ON mdr.dietary_restriction_id = udr.dietary_restriction_id
            WHERE mdr.meal_id = m.id
        ) OR :ignore_preferences = TRUE)
        AND (m.prep_time <= :max_prep_time OR :max_prep_time IS NULL)
)
SELECT id, title, meal_type, prep_time, cuisine_id
FROM eligible_meals
WHERE rank <= :limit
ORDER BY diet_match, cuisine_match, rank
"""

# Query for optimized meal search with multiple criteria
SEARCH_MEALS = """
WITH search_results AS (
    SELECT 
        m.id, 
        m.title, 
        m.description, 
        m.cuisine_id,
        c.name as cuisine_name,
        m.ratings,
        m.calories,
        m.prep_time,
        m.cook_time,
        m.total_time,
        CASE 
            WHEN m.title ILIKE :search_term THEN 3
            WHEN m.description ILIKE :search_term THEN 2
            ELSE 1
        END as relevance_score,
        ts_rank(
            to_tsvector('english', COALESCE(m.title, '') || ' ' || COALESCE(m.description, '')), 
            plainto_tsquery('english', :search_term)
        ) as text_rank,
        ROW_NUMBER() OVER (
            ORDER BY 
                CASE WHEN m.title ILIKE :search_term THEN 3
                     WHEN m.description ILIKE :search_term THEN 2
                     ELSE 1
                END DESC,
                ts_rank(
                    to_tsvector('english', COALESCE(m.title, '') || ' ' || COALESCE(m.description, '')), 
                    plainto_tsquery('english', :search_term)
                ) DESC,
                m.ratings DESC NULLS LAST
        ) as rank
    FROM "Meal" m
    LEFT JOIN "Cuisine" c ON m.cuisine_id = c.id
    WHERE 
        (
            m.title ILIKE '%' || :search_term || '%' OR 
            m.description ILIKE '%' || :search_term || '%' OR
            c.name ILIKE '%' || :search_term || '%'
        )
        AND (:cuisine_id IS NULL OR m.cuisine_id = :cuisine_id)
        AND (:max_prep_time IS NULL OR m.prep_time <= :max_prep_time)
        AND (:min_rating IS NULL OR m.ratings >= :min_rating)
        AND (
            :dietary_restriction_id IS NULL OR 
            m.id IN (
                SELECT meal_id 
                FROM "MealDietaryRestriction" 
                WHERE dietary_restriction_id = :dietary_restriction_id
            )
        )
)
SELECT 
    id, 
    title, 
    description, 
    cuisine_id, 
    cuisine_name, 
    ratings, 
    calories, 
    prep_time, 
    cook_time,
    total_time
FROM search_results
WHERE rank <= :limit
ORDER BY relevance_score DESC, text_rank DESC, ratings DESC NULLS LAST
"""

# Query for retrieving detailed meal information
GET_MEAL_DETAILS = """
SELECT 
    m.id,
    m.title,
    m.description,
    m.prep_time,
    m.cook_time,
    m.total_time,
    m.servings,
    m.calories,
    m.ratings,
    c.id as cuisine_id,
    c.name as cuisine_name,
    (
        SELECT json_agg(json_build_object(
            'id', dr.id,
            'name', dr.name
        ))
        FROM "MealDietaryRestriction" mdr
        JOIN "DietaryRestriction" dr ON mdr.dietary_restriction_id = dr.id
        WHERE mdr.meal_id = m.id
    ) as dietary_restrictions,
    (
        SELECT json_agg(json_build_object(
            'id', i.id,
            'name', i.name,
            'amount', mi.amount
        ))
        FROM "MealIngredient" mi
        JOIN "Ingredient" i ON mi.ingredient_id = i.id
        WHERE mi.meal_id = m.id
    ) as ingredients,
    (
        SELECT COUNT(*) 
        FROM recommendation_interactions 
        WHERE meal_id = m.id AND content_type = 'meal'
    ) as interaction_count
FROM "Meal" m
LEFT JOIN "Cuisine" c ON m.cuisine_id = c.id
WHERE m.id = :meal_id
"""

# Query for getting user recommendations with advanced personalization
GET_PERSONALIZED_RECOMMENDATIONS = """
WITH user_interactions AS (
    SELECT meal_id, content_type, interaction_type, created_at,
        ROW_NUMBER() OVER (PARTITION BY meal_id, content_type ORDER BY created_at DESC) as row_num
    FROM recommendation_interactions
    WHERE user_id = :user_id
),
recent_interactions AS (
    SELECT meal_id, content_type, interaction_type, created_at
    FROM user_interactions
    WHERE row_num = 1
),
user_dietary_preferences AS (
    SELECT dietary_restriction_id
    FROM "UserDietaryPreference"
    WHERE user_id = :user_id
),
user_cuisine_preferences AS (
    SELECT 
        m.cuisine_id, 
        COUNT(*) as interaction_count,
        ROW_NUMBER() OVER (ORDER BY COUNT(*) DESC) as rank
    FROM recommendation_interactions ri
    JOIN "Meal" m ON ri.meal_id = m.id AND ri.content_type = 'meal'
    WHERE ri.user_id = :user_id
    GROUP BY m.cuisine_id
    HAVING COUNT(*) > 1
),
content_based_candidates AS (
    SELECT 
        ce2.meal_id,
        ce2.content_type,
        1 - (ce2.embedding <=> ce1.embedding) as similarity_score,
        ROW_NUMBER() OVER (PARTITION BY ce1.meal_id ORDER BY 1 - (ce2.embedding <=> ce1.embedding) DESC) as rank
    FROM recent_interactions ri
    JOIN content_embeddings ce1 ON ri.meal_id = ce1.meal_id AND ri.content_type = ce1.content_type
    JOIN content_embeddings ce2 ON ce1.content_type = ce2.content_type
    WHERE ce2.meal_id != ri.meal_id
    AND NOT EXISTS (
        SELECT 1 FROM user_interactions ui 
        WHERE ui.meal_id = ce2.meal_id AND ui.content_type = ce2.content_type
    )
),
collaborative_candidates AS (
    SELECT 
        ri2.meal_id,
        ri2.content_type,
        COUNT(DISTINCT ri2.user_id) as user_count,
        ROW_NUMBER() OVER (ORDER BY COUNT(DISTINCT ri2.user_id) DESC) as rank
    FROM recent_interactions ri
    JOIN recommendation_interactions ri2 ON ri.meal_id = ri2.meal_id AND ri.content_type = ri2.content_type
    JOIN recommendation_interactions ri3 ON ri3.user_id = ri2.user_id AND ri3.user_id != :user_id
    WHERE NOT EXISTS (
        SELECT 1 FROM user_interactions ui 
        WHERE ui.meal_id = ri3.meal_id AND ui.content_type = ri3.content_type
    )
    AND ri3.meal_id != ri.meal_id
    GROUP BY ri3.meal_id, ri3.content_type
),
final_candidates AS (
    -- Content-based candidates
    SELECT 
        c.meal_id,
        c.content_type,
        CASE 
            WHEN c.content_type = 'meal' THEN m.title
            WHEN c.content_type = 'recipe' THEN r.name
        END as title,
        c.similarity_score * 0.8 as score,
        1 as source_type
    FROM content_based_candidates c
    LEFT JOIN "Meal" m ON c.meal_id = m.id AND c.content_type = 'meal'
    LEFT JOIN "Recipe" r ON c.meal_id = r.id AND c.content_type = 'recipe'
    WHERE c.rank <= :limit * 2
    
    UNION ALL
    
    -- Collaborative candidates
    SELECT 
        c.meal_id,
        c.content_type,
        CASE 
            WHEN c.content_type = 'meal' THEN m.title
            WHEN c.content_type = 'recipe' THEN r.name
        END as title,
        c.user_count / (SELECT MAX(user_count) FROM collaborative_candidates) * 0.7 as score,
        2 as source_type
    FROM collaborative_candidates c
    LEFT JOIN "Meal" m ON c.meal_id = m.id AND c.content_type = 'meal'
    LEFT JOIN "Recipe" r ON c.meal_id = r.id AND c.content_type = 'recipe'
    WHERE c.rank <= :limit * 2
    
    UNION ALL
    
    -- Popular items from user's preferred cuisines
    SELECT 
        m.id as meal_id,
        'meal' as content_type,
        m.title,
        0.6 - (0.1 * ucp.rank) as score,
        3 as source_type
    FROM "Meal" m
    JOIN user_cuisine_preferences ucp ON m.cuisine_id = ucp.cuisine_id
    WHERE NOT EXISTS (
        SELECT 1 FROM user_interactions ui 
        WHERE ui.meal_id = m.id AND ui.content_type = 'meal'
    )
    AND ucp.rank <= 3
    
    UNION ALL
    
    -- Items matching user's dietary preferences
    SELECT 
        m.id as meal_id,
        'meal' as content_type,
        m.title,
        0.5 as score,
        4 as source_type
    FROM "Meal" m
    JOIN "MealDietaryRestriction" mdr ON m.id = mdr.meal_id
    JOIN user_dietary_preferences udp ON mdr.dietary_restriction_id = udp.dietary_restriction_id
    WHERE NOT EXISTS (
        SELECT 1 FROM user_interactions ui 
        WHERE ui.meal_id = m.id AND ui.content_type = 'meal'
    )
    
    UNION ALL
    
    -- Generally popular items as fallback
    SELECT 
        m.id as meal_id,
        'meal' as content_type,
        m.title,
        0.4 as score,
        5 as source_type
    FROM "Meal" m
    JOIN (
        SELECT meal_id, COUNT(*) as count
        FROM recommendation_interactions
        WHERE content_type = 'meal'
        GROUP BY meal_id
        ORDER BY count DESC
        LIMIT :limit
    ) popular ON m.id = popular.meal_id
    WHERE NOT EXISTS (
        SELECT 1 FROM user_interactions ui 
        WHERE ui.meal_id = m.id AND ui.content_type = 'meal'
    )
),
ranked_candidates AS (
    SELECT 
        meal_id,
        content_type,
        title,
        score,
        source_type,
        ROW_NUMBER() OVER (
            PARTITION BY meal_id, content_type 
            ORDER BY score DESC
        ) as dedupe_rank
    FROM final_candidates
    WHERE (:content_type IS NULL OR content_type = :content_type)
)
SELECT meal_id as id, content_type, title, score
FROM ranked_candidates
WHERE dedupe_rank = 1
ORDER BY score DESC
LIMIT :limit
"""

# Query for getting trending content by category
GET_TRENDING_BY_CATEGORY = """
WITH trending_by_category AS (
    SELECT 
        ri.meal_id,
        ri.content_type,
        c.name as category,
        CASE 
            WHEN ri.content_type = 'meal' THEN m.title
            WHEN ri.content_type = 'recipe' THEN r.name
        END as title,
        COUNT(*) as interaction_count,
        ROW_NUMBER() OVER (
            PARTITION BY c.name
            ORDER BY COUNT(*) DESC
        ) as category_rank
    FROM recommendation_interactions ri
    JOIN "Meal" m ON ri.meal_id = m.id AND ri.content_type = 'meal'
    LEFT JOIN "Recipe" r ON ri.meal_id = r.id AND ri.content_type = 'recipe'
    JOIN "Cuisine" c ON m.cuisine_id = c.id
    WHERE ri.created_at > CURRENT_TIMESTAMP - INTERVAL :time_window
    GROUP BY ri.meal_id, ri.content_type, c.name, m.title, r.name
)
SELECT meal_id as id, content_type, category, title, interaction_count as popularity
FROM trending_by_category
WHERE category_rank <= :items_per_category
ORDER BY category, category_rank
"""

# Query for getting recently added content
GET_RECENTLY_ADDED = """
WITH recent_content AS (
    SELECT 
        id as meal_id,
        'meal' as content_type,
        title,
        created_at,
        ROW_NUMBER() OVER (ORDER BY created_at DESC) as rank
    FROM "Meal" 
    WHERE created_at IS NOT NULL
    
    UNION ALL
    
    SELECT 
        id as meal_id,
        'recipe' as content_type,
        name as title,
        created_at,
        ROW_NUMBER() OVER (ORDER BY created_at DESC) as rank
    FROM "Recipe"
    WHERE created_at IS NOT NULL
)
SELECT meal_id as id, content_type, title
FROM recent_content
WHERE rank <= :limit
ORDER BY created_at DESC
"""
////////////////////////////////////////////////////////////////////////////////

│   ├── repo.py

////////////////////////////////////////////////////////////////////////////////
"""
Repositories for data access.
All repositories are consolidated in this module for easier maintenance.
"""
from typing import List, Dict, Any, Optional, Tuple
import logging
from datetime import datetime

from data.database import execute_query
import data.queries as queries
from config import CONTENT_TYPES, MIN_COMMON_ITEMS

logger = logging.getLogger(__name__)

class ContentEmbeddingRepository:
    """Repository for content embeddings."""
    
    def save_embedding(self, meal_id: str, content_type: str, embedding: List[float]) -> bool:
        """
        Save or update a content embedding.
        
        Args:
            meal_id: The ID of the content
            content_type: The type of content ('meal', 'recipe')
            embedding: The vector embedding
            
        Returns:
            bool: Success status
        """
        try:
            execute_query(
                queries.SAVE_EMBEDDING,
                {
                    "meal_id": meal_id,
                    "content_type": content_type,
                    "embedding": embedding
                },
                is_transaction=True
            )
            return True
        except Exception as e:
            logger.error(f"Error saving embedding: {e}")
            return False
    
    def get_embedding(self, meal_id: str, content_type: str) -> Optional[List[float]]:
        """
        Get the embedding for specific content.
        
        Args:
            meal_id: The ID of the content
            content_type: The type of content
            
        Returns:
            The embedding vector or None if not found
        """
        result = execute_query(
            queries.GET_EMBEDDING,
            {"meal_id": meal_id, "content_type": content_type}
        )
        
        row = result.fetchone()
        return row[0] if row else None
    
    def find_similar_content(
        self, 
        embedding: List[float], 
        content_type: Optional[str] = None, 
        exclude_ids: List[str] = None,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Find content with similar embeddings.
        
        Args:
            embedding: The source embedding to compare against
            content_type: Optional filter for content type
            exclude_ids: List of content IDs to exclude
            limit: Maximum number of results
            
        Returns:
            List of similar content items with similarity scores
        """
        params = {"embedding": embedding, "limit": limit}
        
        # Build query parts
        type_filter = ""
        if content_type:
            type_filter = "AND ce.content_type = :content_type"
            params["content_type"] = content_type
        
        exclude_clause = ""
        if exclude_ids and len(exclude_ids) > 0:
            placeholder_list = ','.join([f':exclude_{i}' for i in range(len(exclude_ids))])
            exclude_clause = f"AND ce.meal_id NOT IN ({placeholder_list})"
            for i, id_val in enumerate(exclude_ids):
                params[f"exclude_{i}"] = id_val
        
        # Execute query
        formatted_query = queries.FIND_SIMILAR_CONTENT_BASE.format(
            type_filter=type_filter,
            exclude_clause=exclude_clause
        )
        
        result = execute_query(
            formatted_query,
            params
        )
        
        items = []
        for row in result:
            items.append({
                "id": row[0],
                "content_type": row[1],
                "title": row[2],
                "similarity": row[3]
            })
        
        return items
    
    def get_content_without_embeddings(self, content_type: str, limit: int = 500) -> List[Tuple[str, str, str]]:
        """
        Get content items that don't have embeddings yet.
        
        Args:
            content_type: The type of content
            limit: Maximum number of items to retrieve
            
        Returns:
            List of tuples (id, title, content) for items without embeddings
        """
        if content_type == 'meal':
            result = execute_query(
                queries.GET_MEALS_WITHOUT_EMBEDDINGS,
                {"limit": limit}
            )
        elif content_type == 'recipe':
            result = execute_query(
                queries.GET_RECIPES_WITHOUT_EMBEDDINGS,
                {"limit": limit}
            )
        else:
            return []
        
        return [(row[0], row[1] or '', row[2] or '') for row in result.fetchall()]
    
    def get_meal_ingredients(self, meal_id: str) -> List[Dict[str, Any]]:
        """
        Get ingredients for a meal.
        
        Args:
            meal_id: The ID of the meal
            
        Returns:
            List of ingredients
        """
        result = execute_query(
            queries.GET_MEAL_INGREDIENTS,
            {"meal_id": meal_id}
        )
        
        ingredients = []
        for row in result:
            ingredients.append({
                "id": row[0],
                "name": row[1],
                "amount": row[2]
            })
        
        return ingredients
    
    def get_recipe_ingredients(self, recipe_id: str) -> List[Dict[str, Any]]:
        """
        Get ingredients for a recipe.
        
        Args:
            recipe_id: The ID of the recipe
            
        Returns:
            List of ingredients
        """
        result = execute_query(
            queries.GET_RECIPE_INGREDIENTS,
            {"recipe_id": recipe_id}
        )
        
        ingredients = []
        for row in result:
            ingredients.append({
                "id": row[0],
                "name": row[1],
                "amount": row[2]
            })
        
        return ingredients
    
    def get_similar_by_ingredients(
        self,
        meal_id: str,
        content_type: str,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Get meals similar by ingredients.
        
        Args:
            meal_id: The ID of the meal
            content_type: The type of content
            limit: Maximum number of results
            
        Returns:
            List of similar meals
        """
        if content_type != 'meal':
            return []
        
        result = execute_query(
            queries.GET_SIMILAR_MEALS_BY_INGREDIENTS,
            {"meal_id": meal_id, "limit": limit}
        )
        
        items = []
        for row in result:
            items.append({
                "id": row[0],
                "content_type": "meal",
                "title": row[1],
                "similarity": row[2] / 10.0  # Normalize to 0-1 range
            })
        
        return items

class InteractionRepository:
    """Repository for user interactions."""
    
    def record_interaction(
        self, 
        user_id: str, 
        meal_id: str, 
        content_type: str, 
        interaction_type: str
    ) -> bool:
        """
        Record a user interaction with content.
        
        Args:
            user_id: The ID of the user
            meal_id: The ID of the content
            content_type: The type of content ('meal', 'recipe')
            interaction_type: The type of interaction ('view', 'like', 'save', 'cook')
            
        Returns:
            bool: Success status
        """
        try:
            if content_type not in CONTENT_TYPES:
                raise ValueError(f"Invalid content type: {content_type}")
                
            execute_query(
                queries.RECORD_INTERACTION,
                {
                    "user_id": user_id,
                    "meal_id": meal_id,
                    "content_type": content_type,
                    "interaction_type": interaction_type
                },
                is_transaction=True
            )
            return True
        except Exception as e:
            logger.error(f"Error recording interaction: {e}")
            return False
    
    def get_user_recent_interactions(
        self, 
        user_id: str, 
        content_type: Optional[str] = None,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Get recent interactions for a user.
        
        Args:
            user_id: The ID of the user
            content_type: Optional filter for content type
            limit: Maximum number of interactions to retrieve
            
        Returns:
            List of recent interactions
        """
        params = {"user_id": user_id, "limit": limit}
        
        type_filter = ""
        if content_type:
            if content_type not in CONTENT_TYPES:
                raise ValueError(f"Invalid content type: {content_type}")
            type_filter = "AND content_type = :content_type"
            params["content_type"] = content_type
            
        # Format the query with the type filter
        formatted_query = queries.GET_USER_RECENT_INTERACTIONS_BASE.format(
            type_filter=type_filter
        )
        
        result = execute_query(
            formatted_query,
            params
        )
        
        interactions = []
        for row in result:
            interactions.append({
                "meal_id": row[0],
                "content_type": row[1],
                "interaction_type": row[2],
                "created_at": row[3]
            })
        
        return interactions
    
    def get_trending_content(
        self, 
        content_type: str = 'all', 
        time_window: str = 'day',
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Get trending content based on recent interactions.
        
        Args:
            content_type: The type of content ('meal', 'recipe', 'all')
            time_window: Time window ('day', 'week', 'month')
            limit: Maximum number of items
            
        Returns:
            List of trending content items with popularity scores
        """
        # Determine time interval
        time_clause = "NOW() - INTERVAL '1 day'"
        if time_window == "week":
            time_clause = "NOW() - INTERVAL '7 days'"
        elif time_window == "month":
            time_clause = "NOW() - INTERVAL '30 days'"
        
        type_filter = ""
        params = {"limit": limit}
        
        if content_type != 'all':
            if content_type not in CONTENT_TYPES:
                raise ValueError(f"Invalid content type: {content_type}")
            type_filter = "AND ri.content_type = :content_type"
            params["content_type"] = content_type
        
        # Format the query with the time clause and type filter
        formatted_query = queries.GET_TRENDING_MEALS_BASE.format(
            time_clause=time_clause,
            type_filter=type_filter
        )
        
        result = execute_query(
            formatted_query,
            params
        )
        
        trending_items = []
        for row in result:
            trending_items.append({
                "id": row[0],
                "content_type": row[1],
                "title": row[2],
                "popularity": row[3]
            })
        
        return trending_items
    
    def find_similar_users(
        self, 
        user_id: str, 
        min_common_items: int = MIN_COMMON_ITEMS, 
        limit: int = 10
    ) -> List[str]:
        """
        Find users with similar interaction patterns.
        
        Args:
            user_id: The ID of the user
            min_common_items: Minimum number of common items to consider users similar
            limit: Maximum number of similar users to retrieve
            
        Returns:
            List of similar user IDs
        """
        result = execute_query(
            queries.FIND_SIMILAR_USERS,
            {
                "user_id": user_id, 
                "min_common_items": min_common_items,
                "limit": limit
            }
        )
        
        return [row[0] for row in result]
    
    def get_content_from_similar_users(
        self, 
        similar_users: List[str],
        user_id: str,
        content_type: Optional[str] = None,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Get content items that similar users interacted with.
        
        Args:
            similar_users: List of similar user IDs
            user_id: The ID of the current user (to exclude content they've already interacted with)
            content_type: Optional filter for content type
            limit: Maximum number of content items to retrieve
            
        Returns:
            List of content items with interaction counts
        """
        if not similar_users:
            return []
        
        # Create parameter placeholders for similar users
        user_placeholders = ','.join([f':user_{i}' for i in range(len(similar_users))])
        params = {"user_id": user_id, "limit": limit}
        
        # Add similar user IDs to parameters
        for i, similar_user in enumerate(similar_users):
            params[f"user_{i}"] = similar_user
        
        # Add content type filter if specified
        type_filter = ""
        if content_type:
            if content_type not in CONTENT_TYPES:
                raise ValueError(f"Invalid content type: {content_type}")
            type_filter = "AND ri.content_type = :content_type"
            params["content_type"] = content_type
        
        # Format the query with the user placeholders and type filter
        formatted_query = queries.GET_MEALS_FROM_SIMILAR_USERS_BASE.format(
            user_placeholders=user_placeholders,
            type_filter=type_filter
        )
        
        result = execute_query(
            formatted_query,
            params
        )
        
        content_items = []
        for row in result:
            content_items.append({
                "id": row[0],
                "content_type": row[1],
                "interaction_count": row[2],
                "title": row[3]
            })
        
        return content_items
    
    def get_cuisine_recommendations(
        self, 
        cuisine_id: str, 
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Get meals in a specific cuisine.
        
        Args:
            cuisine_id: The ID of the cuisine
            limit: Maximum number of meals to retrieve
            
        Returns:
            List of meals in the cuisine
        """
        result = execute_query(
            queries.GET_CUISINE_MEALS,
            {"cuisine_id": cuisine_id, "limit": limit}
        )
        
        meals = []
        for row in result:
            meals.append({
                "id": row[0],
                "content_type": "meal",
                "title": row[1]
            })
        
        return meals
    
    def get_dietary_recommendations(
        self, 
        dietary_restriction_id: str, 
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Get meals that match a dietary restriction.
        
        Args:
            dietary_restriction_id: The ID of the dietary restriction
            limit: Maximum number of meals to retrieve
            
        Returns:
            List of meals matching the dietary restriction
        """
        result = execute_query(
            queries.GET_DIETARY_PREFERENCE_MEALS,
            {"dietary_restriction_id": dietary_restriction_id, "limit": limit}
        )
        
        meals = []
        for row in result:
            meals.append({
                "id": row[0],
                "content_type": "meal",
                "title": row[1]
            })
        
        return meals
    
    def get_user_dietary_preferences(
        self, 
        user_id: str
    ) -> List[Dict[str, Any]]:
        """
        Get a user's dietary preferences.
        
        Args:
            user_id: The ID of the user
            
        Returns:
            List of dietary preferences
        """
        result = execute_query(
            queries.GET_USER_DIETARY_PREFERENCES,
            {"user_id": user_id}
        )
        
        preferences = []
        for row in result:
            preferences.append({
                "id": row[0],
                "name": row[1]
            })
        
        return preferences
    
    def add_user_dietary_preference(
        self, 
        user_id: str, 
        dietary_restriction_id: int
    ) -> bool:
        """
        Add a dietary preference for a user.
        
        Args:
            user_id: The ID of the user
            dietary_restriction_id: The ID of the dietary restriction
            
        Returns:
            Success status
        """
        try:
            execute_query(
                """
                INSERT INTO "UserDietaryPreference" (user_id, dietary_restriction_id)
                VALUES (:user_id, :dietary_restriction_id)
                ON CONFLICT (user_id, dietary_restriction_id) DO NOTHING
                """,
                {
                    "user_id": user_id,
                    "dietary_restriction_id": dietary_restriction_id
                },
                is_transaction=True
            )
            return True
        except Exception as e:
            logger.error(f"Error adding dietary preference: {e}")
            return False
////////////////////////////////////////////////////////////////////////////////

│   └── signature.md

////////////////////////////////////////////////////////////////////////////////
#merged

IngID,ingredient,frequency,generic_name,wikilink,wikiimage,FlavorDB_Category,Dietrx_Category,Flavor_DB_Link,flavordb_id,Diet_rx_link,ingredient_raw,serving size (g),energy (kcal),protein (g),carbohydrate (g),total fat (g),total sugar (g)
0,salt,48195,Salt,https://en.wikipedia.org/wiki/Salt,https://upload.wikimedia.org/wikipedia/commons/thumb/0/07/Comparison_of_Table_Salt_with_Kitchen_Salt.png/220px-Comparison_of_Table_Salt_with_Kitchen_Salt.png,,Additive,Salt~https://cosylab.iiitd.edu.in/flavordb/entity_details?id=778,778,,,,,,,,
1,onion,35453,Onion,https://en.wikipedia.org/wiki/Onion,https://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/Mixed_onions.jpg/220px-Mixed_onions.jpg,Vegetable-Bulb,Vegetable,Onion~https://cosylab.iiitd.edu.in/flavordb/entity_details?id=348,348,onion~https://cosylab.iiitd.edu.in/dietrx/get_food?food_id=Plant+ID%3A4679||welsh onion~https://cosylab.iiitd.edu.in/dietrx/get_food?food_id=Plant+ID%3A35875,,,,,,,
2,butter,30038,Butter,https://en.wikipedia.org/wiki/Butter,https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/%C5%A0v%C3%A9dsk%C3%BD_kol%C3%A1%C4%8D_naruby_904_%28cropped%29.JPG/235px-%C5%A0v%C3%A9dsk%C3%BD_kol%C3%A1%C4%8D_naruby_904_%28cropped%29.JPG,,Dairy,Butter~https://cosylab.iiitd.edu.in/flavordb/entity_details?id=60,60,butter~https://cosylab.iiitd.edu.in/dietrx/get_food?food_id=Dairy+ID%3A5,,,,,,,
3,water,26790,Water,https://en.wikipedia.org/wiki/Fresh_Water,https://upload.wikimedia.org/wikipedia/commons/5/5e/Amazonas%2C_Iquitos_-_Leticia%2C_Kolumbien_%2811472506936%29.jpg,,Additive,Water~https://cosylab.iiitd.edu.in/flavordb/entity_details?id=794,794,,,,,,,,
4,garlic clove,25636,Garlic,https://en.wikipedia.org/wiki/Garlic,https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Garlic_whole.jpg/440px-Garlic_whole.jpg,,Herb,Garlic~https://cosylab.iiitd.edu.in/flavordb/entity_details?id=259,259,garlic~https://cosylab.iiitd.edu.in/dietrx/get_food?food_id=Plant+ID%3A4682||wild garlic~https://cosylab.iiitd.edu.in/dietrx/get_food?food_id=Plant+ID%3A4684,,,,,,,
5,olive oil,23799,Olive,https://en.wikipedia.org/wiki/Olive_oil,https://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Oliven_V1.jpg/250px-Oliven_V1.jpg,,Plant Derivative,Olive~https://cosylab.iiitd.edu.in/flavordb/entity_details?id=307,307,common olive~https://cosylab.iiitd.edu.in/dietrx/get_food?food_id=Plant+ID%3A4146||autumn olive~https://cosylab.iiitd.edu.in/dietrx/get_food?food_id=Plant+ID%3A43233||chinese white olive~https://cosylab.iiitd.edu.in/dietrx/get_food?food_id=Plant+ID%3A300208||russian olive~https://cosylab.iiitd.edu.in/dietrx/get_food?food_id=Plant+ID%3A36777||chinese olive~https://cosylab.iiitd.edu.in/dietrx/get_food?food_id=Plant+ID%3A246350,olive oil,100.0,900.0,0.0,0.0,100.0,0.0


# data/RecipeDB_general.csv
Recipe_id,Calories,cook_time,prep_time,servings,Recipe_title,total_time,url,Region,Sub_region,Continent,Source,img_url,"Carbohydrate, by difference (g)",Energy (kcal),Protein (g),Total lipid (fat) (g),Utensils,Processes,vegan,pescetarian,ovo_vegetarian,lacto_vegetarian,ovo_lacto_vegetarian
2610,196.0,30,15,4,Egyptian Lentil Soup,45,http://allrecipes.com/recipe/222661/egyptian-lentil-soup/,Middle Eastern,Egyptian,African,AllRecipes,https://images.media-allrecipes.com/userphotos/560x315/5196784.jpg,146.7606,805.6975,49.554,5.6564,,place||heat||cook||remove||cool||blend||smooth||stir||heat,0.0,0.0,0.0,0.0,0.0
2611,80.0,35,10,4,Egyptian Green Beans with Carrots,45,http://allrecipes.com/recipe/233456/egyptian-green-beans-with-carrots/,Middle Eastern,Egyptian,African,AllRecipes,https://images.media-allrecipes.com/userphotos/560x315/2619313.jpg,39.3312,386.767,15.5638,19.7239,pot,heat||heat||cook||stir||stir||cook||stirring||pour||stir||boil||add||boil||simmer,0.0,0.0,0.0,0.0,0.0
2612,339.0,120,15,4,Egyptian Bamia,135,http://allrecipes.com/recipe/227986/egyptian-bamia/,Middle Eastern,Egyptian,African,AllRecipes,https://images.media-allrecipes.com/userphotos/560x315/3840150.jpg,34.0004,1762.7662,82.9034,146.8971,saucepan||oven||dish||oven,heat||heat||cook||stir||mix||cook||stir||stir||season||boil||simmer||stir||preheat||stir||boil||cover||bake,0.0,0.0,0.0,0.0,0.0
2613,409.0,15,15,3,Magpie's Easy Falafel Cakes,60,http://allrecipes.com/recipe/143113/magpies-easy-falafel-cakes/,Middle Eastern,Egyptian,African,AllRecipes,https://images.media-allrecipes.com/userphotos/560x315/5229672.jpg,225.1172,1686.8298,67.8589,62.4829,skillet||processor||bowl||cup||dish||tablespoon||skillet,cook||smooth||transfer||stir||cover||chill||place||roll||heat||heat||cook,0.0,0.0,0.0,1.0,0.0
2614,45.0,5,20,24,Dukkah,25,http://allrecipes.com/recipe/79684/dukkah/,Middle Eastern,Egyptian,African,AllRecipes,https://images.media-allrecipes.com/userphotos/560x315/4572970.jpg,83.0609,1006.238,26.18,73.1713,oven||sheet||skillet||bowl||skillet||pan||processor||bowl||processor||bowl,preheat||place||pour||fold||cover||remove||cool||heat||stirring||pop||transfer||process||pour||place||process||stir||season||mix,1.0,1.0,0.0,0.0,0.0
2615,934.0,30,30,8,Om Ali,60,http://allrecipes.com/recipe/19898/om-ali/,Middle Eastern,Egyptian,African,AllRecipes,https://images.media-allrecipes.com/userphotos/560x315/1101880.jpg,543.3028,4117.4667,46.5988,212.1542,oven||dish||oven||oven||oven||bowl||dish||saucepan||dish||oven,preheat||place||place||remove||preheat||break||stir||spread||boil||heat||beat||cream||spread||place||serve,0.0,0.0,0.0,0.0,0.0




/home/mealflow/mealflow/Recommend/data/RecipeDB_ingredient_phrase.csv
recipe_no,ingredient_Phrase,ingredient,state,quantity,unit,temp,df,size,ing_id,ndb_id,M_or_A
2610,3 cups water,water,,3,cups,,,,3,14555,M
2610,1 cup red lentils,red lentil,,1,cup,,,,452,16144,A
2610,"1 roma tomato , quartered",rom tomato,quartered,1,,,,,180,93600,A
2610,"1 carrot , quartered",carrot,quartered,1,,,,,21,11124,M
2610,"1 small onion , quartered",onion,quartered,1,,,,small,1,11282,M
2610,"4 cloves garlic , quartered",garlic,quartered,4,cloves,,,,10,11215,A
2610,2 teaspoons ground cumin,cumin,ground,2,teaspoons,,,,20,2014,M
2610,1/2 teaspoon sea salt,sea salt,,1/2,teaspoon,,,,90,93600,A
2610,1/2 teaspoon cracked black pepper,black pepper,cracked,1/2,teaspoon,,,,9,2030,A
2610,1/4 teaspoon ground coriander,coriander,ground,1/4,teaspoon,,,,57,2013,M
2611,1 tablespoon vegetable oil,vegetable oil,,1,tablespoon,,,,19,4513,A



/home/mealflow/mealflow/Recommend/data/RecipeDB_ingredient_flavor.csv
IngID,ingredient,frequency,generic_name,wikilink,wikiimage,FlavorDB_Category,Dietrx_Category,Flavor_DB_Link,flavordb_id,Diet_rx_link
0,salt,48195,Salt,https://en.wikipedia.org/wiki/Salt,https://upload.wikimedia.org/wikipedia/commons/thumb/0/07/Comparison_of_Table_Salt_with_Kitchen_Salt.png/220px-Comparison_of_Table_Salt_with_Kitchen_Salt.png,,Additive,Salt~https://cosylab.iiitd.edu.in/flavordb/entity_details?id=778,778,
1,onion,35453,Onion,https://en.wikipedia.org/wiki/Onion,https://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/Mixed_onions.jpg/220px-Mixed_onions.jpg,Vegetable-Bulb,Vegetable,Onion~https://cosylab.iiitd.edu.in/flavordb/entity_details?id=348,348,onion~https://cosylab.iiitd.edu.in/dietrx/get_food?food_id=Plant+ID%3A4679||welsh onion~https://cosylab.iiitd.edu.in/dietrx/get_food?food_id=Plant+ID%3A35875
2,butter,30038,Butter,https://en.wikipedia.org/wiki/Butter,https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/%C5%A0v%C3%A9dsk%C3%BD_kol%C3%A1%C4%8D_naruby_904_%28cropped%29.JPG/235px-%C5%A0v%C3%A9dsk%C3%BD_kol%C3%A1%C4%8D_naruby_904_%28cropped%29.JPG,,Dairy,Butter~https://cosylab.iiitd.edu.in/flavordb/entity_details?id=60,60,butter~https://cosylab.iiitd.edu.in/dietrx/get_food?food_id=Dairy+ID%3A5









////////////////////////////////////////////////////////////////////////////////

├── db.py

////////////////////////////////////////////////////////////////////////////////
"""
Database connection module.
Provides database connection pool and transaction management.
"""
from sqlalchemy import create_engine, text
from contextlib import contextmanager
from typing import Generator
import logging

from config import DATABASE_URL

logger = logging.getLogger(__name__)

# Create database engine with connection pooling
engine = create_engine(
    DATABASE_URL, 
    pool_size=10, 
    max_overflow=20,
    pool_pre_ping=True,  # Check connection validity before using
    pool_recycle=300,    # Recycle connections after 5 minutes
)

@contextmanager
def get_db():
    """Get a database connection from the pool."""
    connection = engine.connect()
    try:
        yield connection
    finally:
        connection.close()

@contextmanager
def get_transaction():
    """Get a database connection with transaction."""
    connection = engine.connect()
    transaction = connection.begin()
    try:
        yield connection
        transaction.commit()
    except Exception as e:
        transaction.rollback()
        logger.error(f"Transaction failed: {e}")
        raise
    finally:
        connection.close()

def execute_query(query, params=None, is_transaction=False):
    """
    Execute a database query with parameters.
    
    Args:
        query: SQL query text
        params: Query parameters
        is_transaction: Whether to execute within a transaction
        
    Returns:
        Query result
    """
    manager = get_transaction if is_transaction else get_db
    
    with manager() as conn:
        result = conn.execute(text(query), params or {})
        return result

def test_connection():
    """
    Test the database connection.
    
    Returns:
        Boolean indicating connection success
    """
    try:
        with get_db() as conn:
            result = conn.execute(text("SELECT 1"))
            logger.info("Database connection successful!")
            return True
    except Exception as e:
        logger.error(f"Database connection failed: {e}")
        return False
////////////////////////////////////////////////////////////////////////////////

├── embeddings
│   ├── __init__.py

////////////////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////////////////

│   └── embedding_generator.py

////////////////////////////////////////////////////////////////////////////////
"""
Embedding generator service.
Generates and stores vector embeddings for meals and recipes.
"""
from sentence_transformers import SentenceTransformer
from typing import List, Dict, Any, Optional
import time
import logging

from config import EMBEDDING_MODEL
from data.repositories import ContentEmbeddingRepository

logger = logging.getLogger(__name__)

class EmbeddingGenerator:
    """Service for generating and managing meal embeddings."""
    
    def __init__(self, model_name: str = EMBEDDING_MODEL):
        """
        Initialize the embedding generator.
        
        Args:
            model_name: The name of the sentence transformer model to use
        """
        self.model = SentenceTransformer(model_name)
        self.repository = ContentEmbeddingRepository()
    
    def generate_meal_embeddings(self, batch_size: int = 500) -> int:
        """
        Generate embeddings for meals that don't have them yet.
        
        Args:
            batch_size: Maximum number of meals to process at once
            
        Returns:
            Number of meals processed
        """
        meals = self.repository.get_content_without_embeddings('meal', batch_size)
        logger.info(f"Processing {len(meals)} meals for embedding generation")
        
        count = 0
        for meal_id, title, description in meals:
            # Get ingredients for this meal
            ingredients = self.repository.get_meal_ingredients(meal_id)
            ingredients_text = ", ".join([ing['name'] for ing in ingredients])
            
            # Generate text for embedding - include title, description, and ingredients
            text_for_embedding = f"{title} {description} Ingredients: {ingredients_text}"
            
            # Generate embedding
            embedding = self.model.encode(text_for_embedding)
            
            # Store embedding
            if self.repository.save_embedding(meal_id, 'meal', embedding.tolist()):
                count += 1
            
        logger.info(f"Generated embeddings for {count} meals")
        return count
    
    def generate_recipe_embeddings(self, batch_size: int = 500) -> int:
        """
        Generate embeddings for recipes that don't have them yet.
        
        Args:
            batch_size: Maximum number of recipes to process at once
            
        Returns:
            Number of recipes processed
        """
        recipes = self.repository.get_content_without_embeddings('recipe', batch_size)
        logger.info(f"Processing {len(recipes)} recipes for embedding generation")
        
        count = 0
        for recipe_id, name, instructions in recipes:
            # Get ingredients for this recipe
            ingredients = self.repository.get_recipe_ingredients(recipe_id)
            ingredients_text = ", ".join([ing['name'] for ing in ingredients])
            
            # Generate text for embedding - include name, instructions, and ingredients
            text_for_embedding = f"{name} {instructions} Ingredients: {ingredients_text}"
            
            # Generate embedding
            embedding = self.model.encode(text_for_embedding)
            
            # Store embedding
            if self.repository.save_embedding(recipe_id, 'recipe', embedding.tolist()):
                count += 1
            
        logger.info(f"Generated embeddings for {count} recipes")
        return count
    
    def generate_embedding_for_text(self, text: str) -> List[float]:
        """
        Generate an embedding for arbitrary text.
        
        Args:
            text: The text to encode
            
        Returns:
            The embedding vector
        """
        embedding = self.model.encode(text)
        return embedding.tolist()
    
    def generate_embedding_for_meal(self, meal_id: str, title: str, description: str, ingredients: List[str]) -> bool:
        """
        Generate and store an embedding for a specific meal.
        
        Args:
            meal_id: The ID of the meal
            title: The meal title
            description: The meal description
            ingredients: List of ingredient names
            
        Returns:
            Success status
        """
        ingredients_text = ", ".join(ingredients)
        text_for_embedding = f"{title} {description} Ingredients: {ingredients_text}"
        
        embedding = self.model.encode(text_for_embedding)
        return self.repository.save_embedding(meal_id, 'meal', embedding.tolist())
    
    def generate_all_embeddings(self) -> Dict[str, int]:
        """
        Generate embeddings for all content types.
        
        Returns:
            Dictionary with counts of processed items by type
        """
        meal_count = self.generate_meal_embeddings()
        recipe_count = self.generate_recipe_embeddings()
        
        return {
            "meals": meal_count,
            "recipes": recipe_count
        }


# For command-line execution
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    generator = EmbeddingGenerator()
    result = generator.generate_all_embeddings()
    print(f"Generated embeddings: {result}")
////////////////////////////////////////////////////////////////////////////////

├── main.py

////////////////////////////////////////////////////////////////////////////////
"""
Meal Recommendation Service main application.
This is the entry point for the service.
"""
import uvicorn
import logging
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
import time

from api.endpoints import router as api_router
from utils.scheduler import start_scheduler
from setup import create_recommendation_tables
from embeddings.generator import EmbeddingGenerator
from config import API_HOST, API_PORT, RELOAD

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Request timing middleware
class TimingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        response = await call_next(request)
        process_time = time.time() - start_time
        
        # Add timing header
        response.headers["X-Process-Time"] = f"{process_time:.4f}"
        
        return response

# Startup and shutdown events
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup: Initialize database and run embedding generation
    logger.info("Starting application initialization...")
    
    try:
        # Setup database tables if needed
        create_recommendation_tables()
        logger.info("Database tables created/verified successfully")
        
        # Run initial embedding generation
        logger.info("Starting initial embedding generation...")
        generator = EmbeddingGenerator()
        result = generator.generate_all_embeddings()
        logger.info(f"Initial embedding generation complete: {result}")
        
        # Start the scheduler for background tasks
        logger.info("Starting background scheduler...")
        scheduler_thread = start_scheduler()
        logger.info("Background scheduler started successfully")
        
    except Exception as e:
        logger.error(f"Error during application initialization: {e}")
        # Continue startup even if there are errors to allow for troubleshooting
    
    logger.info("Application initialization complete")
    
    yield
    
    # Shutdown: Nothing to clean up as scheduler runs in daemon thread
    logger.info("Application shutting down...")

# Create FastAPI app with docs disabled
app = FastAPI(
    title="MealFlow Recommendation Service",
    description="API for personalized meal recommendations",
    version="1.0.0",
    docs_url=None,  # Disable Swagger UI
    redoc_url=None,  # Disable ReDoc
    lifespan=lifespan
)

# Add middleware
app.add_middleware(TimingMiddleware)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, replace with specific origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include API router
app.include_router(api_router)

if __name__ == "__main__":
    uvicorn.run(
        "main:app", 
        host=API_HOST, 
        port=API_PORT,
        reload=RELOAD
    )
////////////////////////////////////////////////////////////////////////////////

├── readme.md

////////////////////////////////////////////////////////////////////////////////
# MealFlow Recommendation Service

A comprehensive meal recommendation service built with FastAPI and PostgreSQL with pgvector for efficient similarity searches. This service provides personalized meal and recipe recommendations using multiple recommendation strategies.

## Features

### Multiple Recommendation Strategies

- **Hybrid Recommender**: Combines multiple strategies with fallbacks for robust recommendations
- **User-Based Collaborative Filtering**: Finds users with similar tastes and recommends what they liked
- **Item-Based Collaborative Filtering**: Recommends items similar to those the user has interacted with
- **Content-Based Recommendations**: Uses vector embeddings to find similar content
- **Ingredient-Based Recommendations**: Suggests meals with similar ingredients
- **Popularity-Based Recommendations**: Recommends trending content as a fallback

### Flexible API

- Choose which recommendation strategy to use via API parameters
- Filter by meal type or recipe
- Filter by cuisine or dietary restrictions
- Adjust time windows for trending content
- Get meal recommendations based on time of day

### Efficient Architecture

- Simplified folder structure for better maintainability
- Consolidated modules for easier updates
- Optimized database queries
- Background processing for embedding generation
- Consistent error handling and response formats

## System Architecture

The service is built with FastAPI and uses PostgreSQL with pgvector extension for vector similarity search. It stores embeddings and interaction data in separate tables to work alongside your existing database schema.

## Setup Instructions

### Prerequisites

- Python 3.8+
- PostgreSQL 13+ with pgvector extension
- Make (optional, for using the Makefile)

### Installation

1. Clone this repository:

```bash
git clone https://github.com/yourusername/mealflow-recommendation-service.git
cd mealflow-recommendation-service
```

2. Create a virtual environment (recommended):

```bash
python -m data.loader

This will:
- Create necessary database tables if they don't exist
- Import all recipe data from CSV and JSON files
- Extract and populate cuisine information
- Update foreign key references

You can customize the import settings in your `.env` file, including:
- Data directory path
- File names
- Batch size for efficient imports

## API Documentation

Once the service is running, you can access the interactive API documentation at:

```
http://localhost:8000/docs
```

### Key Endpoints

#### User Recommendations

```
GET /recommend/user/{user_id}
```

Get personalized meal recommendations for a user with options to filter by content type, cuisine, dietary restrictions, and more.

#### Similar Meals

```
GET /recommend/similar/{content_type}/{meal_id}
```

Get meals similar to the specified item with various similarity methods (content-based, interaction-based, ingredient-based).

#### Trending Meals

```
GET /trending/{content_type}
```

Get trending meals based on recent interactions, with adjustable time windows.

#### Cuisine Recommendations

```
GET /recommend/cuisine/{cuisine_id}
```

Get recommended meals from a specific cuisine.

#### Dietary Restriction Recommendations

```
GET /recommend/dietary/{dietary_restriction_id}
```

Get meal recommendations that match specific dietary requirements.

#### Record Interactions

```
POST /interactions
```

Record user interactions with meals (views, likes, saves, etc.) to improve future recommendations.

## Project Structure

```
mealflow-recommendation-service/
├── api/                   # API endpoints and middleware
├── config/                # Configuration settings
├── data/                  # Data access and management
│   ├── loader.py          # Data import script
│   ├── database.py        # Database connection utilities
│   ├── queries.py         # SQL queries
│   └── repositories.py    # Data access repositories
├── embeddings/            # Vector embedding generation
├── services/              # Recommendation services
│   ├── base_recommender.py        # Base interface
│   ├── collaborative_recommender.py
│   ├── content_based_recommender.py
│   ├── hybrid_recommender.py
│   ├── item_based_recommender.py
│   └── popularity_recommender.py
├── setup/                 # Database setup scripts
├── utils/                 # Utility functions
├── main.py                # Application entry point
├── .env                   # Environment variables (not in version control)
├── .env.example           # Example environment file
├── Makefile               # Task automation
└── requirements.txt       # Python dependencies
```

## Production Deployment Considerations

When deploying to production, consider the following:

1. **Database Optimization**:
   - Create appropriate indexes for frequent queries
   - Consider partitioning large tables
   - Set up regular database maintenance

2. **Security**:
   - Use proper authentication for API endpoints
   - Restrict CORS settings to allowed domains
   - Use environment variables for sensitive information

3. **Performance**:
   - Run embedding generation as a separate background process
   - Implement caching for frequent queries
   - Consider using a connection pool for database access

4. **Scalability**:
   - Deploy behind a load balancer
   - Set up multiple worker processes
   - Consider containerization with Docker

5. **Monitoring**:
   - Add detailed logging
   - Set up performance monitoring
   - Implement health check endpoints

## Maintenance and Updates

### Adding New Recommendation Strategies

1. Create a new class that implements the `BaseRecommender` interface
2. Implement the `get_recommendations` method
3. Add the new strategy to the `HybridRecommender` if needed

### Updating Data Models

If you need to update data models:

1. Modify the corresponding repository class
2. Update the database tables as needed
3. Update any affected queries

## Troubleshooting

### Common Issues

1. **Missing pgvector Extension**:
   - Error: "extension 'vector' does not exist"
   - Solution: Install the pgvector extension in your database

2. **Embedding Generation Errors**:
   - Check that the `sentence-transformers` package is properly installed
   - Ensure you have enough memory for the embedding model

3. **Database Connection Issues**:
   - Verify your DATABASE_URL in the .env file
   - Check that PostgreSQL is running
   - Test connection with `make test-db`

4. **Dataset Import Errors**:
   - Ensure your CSV files have the expected format
   - Check for encoding issues in your data files
   - Try importing with smaller batch sizes

## License

MIT License

## Acknowledgments

- SentenceTransformers for the embedding models
- pgvector for PostgreSQL vector similarity search
- FastAPI for the API framework venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install required Python packages:

```bash
pip install -r requirements.txt
```

4. Configure your environment by creating a `.env` file based on `.env.example`:

```bash
cp .env.example .env
# Edit .env with your database credentials and settings
```

5. Install the pgvector extension in your PostgreSQL database:

```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

### Using the Makefile

The project includes a Makefile to simplify common tasks:

```bash
# Set up the complete development environment
make setup

# Test database connection
make test-db

# Load data from CSV and JSON files
make load-data

# Set up database tables only (without data import)
make schema-only

# Generate initial embeddings
make init-embeddings

# Run the service
make run

# Clean up temporary files
make clean

# Show available make commands
make help
```

### Manual Setup

If you prefer not to use the Makefile, you can perform each step manually:

1. Set up database tables:

```bash
python -m setup
```

2. Load data from CSV and JSON files:

```bash
python -m data.loader
```

3. Generate initial embeddings:

```bash
python -c "from embeddings.generator import EmbeddingGenerator; generator = EmbeddingGenerator(); generator.generate_all_embeddings()"
```

4. Start the server:

```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

## Importing Data

The system includes a data loader script that imports the following datasets:

- `RecipeDB_general.csv`: Basic recipe metadata
- `RecipeDB_ingredient_phrase.csv`: Recipe-ingredient relationships
- `RecipeDB_ingredient_flavor.csv`: Ingredient metadata and flavor profiles
- `RecipeDB_instructions.json`: Step-by-step recipe instructions
- `merged.csv`: Merged recipe data with additional metrics

To import your data:

1. Place your data files in the `data` directory
2. Run the data loader:

```bash
python -m
////////////////////////////////////////////////////////////////////////////////

├── requirement.txt

////////////////////////////////////////////////////////////////////////////////
fastapi==0.103.1
uvicorn==0.23.2
sqlalchemy==2.0.20
psycopg2-binary==2.9.7
sentence-transformers==2.2.2
python-dotenv==1.0.0
pandas==2.1.0
numpy==1.25.2
scikit-learn==1.3.0
schedule==1.2.0
pydantic==2.3.0
pytest==7.4.2
flake8==6.1.0
python-multipart==0.0.6
httpx==0.24.1
////////////////////////////////////////////////////////////////////////////////

├── services
│   ├── __init__.py

////////////////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////////////////

│   ├── base_recommender.py

////////////////////////////////////////////////////////////////////////////////
"""
Base recommender interface.
Defines the common interface for all recommendation strategies.
"""
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional

class BaseRecommender(ABC):
    """Base interface for all recommendation strategies."""
    
    @abstractmethod
    def get_recommendations(
        self, 
        user_id: Optional[str] = None,
        meal_id: Optional[str] = None,
        content_type: Optional[str] = None,
        limit: int = 10,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        Get recommendations based on the strategy implementation.
        
        Args:
            user_id: Optional user ID for personalized recommendations
            meal_id: Optional meal ID for similar meal recommendations
            content_type: Optional content type filter ('meal', 'recipe')
            limit: Maximum number of recommendations to return
            kwargs: Additional strategy-specific parameters
            
        Returns:
            List of recommended items
        """
        pass
////////////////////////////////////////////////////////////////////////////////

│   ├── collaborative_recommender.py

////////////////////////////////////////////////////////////////////////////////
"""
Collaborative filtering recommender implementation.
Recommends items based on similar users' interactions.
"""
from typing import List, Dict, Any, Optional
import logging

from services.base_recommender import BaseRecommender
from data.repositories import InteractionRepository
from config import DEFAULT_RECOMMENDATION_LIMIT, MIN_COMMON_ITEMS

logger = logging.getLogger(__name__)

class CollaborativeRecommender(BaseRecommender):
    """
    Collaborative filtering recommendation strategy.
    Finds users with similar interaction patterns and recommends items they've interacted with.
    This is a user-based collaborative filtering approach.
    """
    
    def __init__(self):
        """Initialize the collaborative recommender."""
        self.repository = InteractionRepository()
    
    def get_recommendations(
        self, 
        user_id: Optional[str] = None,
        meal_id: Optional[str] = None,
        content_type: Optional[str] = None,
        limit: int = DEFAULT_RECOMMENDATION_LIMIT,
        min_common_items: int = MIN_COMMON_ITEMS,
        max_similar_users: int = 10,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        Get collaborative filtering recommendations.
        
        Args:
            user_id: The ID of the user
            meal_id: Not used for collaborative recommendations
            content_type: Optional content type filter
            limit: Maximum number of recommendations
            min_common_items: Minimum number of items in common to consider users similar
            max_similar_users: Maximum number of similar users to consider
            kwargs: Additional filters (cuisine, dietary_restriction)
            
        Returns:
            List of recommended items based on similar users
        """
        if not user_id:
            logger.warning("User ID required for collaborative recommendations")
            return []
        
        # Find users with similar interaction patterns
        similar_users = self.repository.find_similar_users(
            user_id, 
            min_common_items=min_common_items,
            limit=max_similar_users
        )
        
        if not similar_users:
            logger.info(f"No similar users found for user {user_id}")
            return []
        
        # Get content that similar users have interacted with
        recommended_items = self.repository.get_content_from_similar_users(
            similar_users,
            user_id,
            content_type=content_type,
            limit=limit
        )
        
        # Apply additional filters if specified
        filtered_items = recommended_items
        
        # Filter by cuisine if specified
        cuisine = kwargs.get('cuisine')
        if cuisine and filtered_items:
            # This would require additional logic to filter by cuisine
            # For simplicity, we're just logging it for now
            logger.info(f"Filtering by cuisine: {cuisine}")
        
        # Filter by dietary restriction if specified
        dietary_restriction = kwargs.get('dietary_restriction')
        if dietary_restriction and filtered_items:
            # This would require additional logic to filter by dietary restriction
            # For simplicity, we're just logging it for now
            logger.info(f"Filtering by dietary restriction: {dietary_restriction}")
        
        # Transform the interaction count to a score between 0 and 1
        if filtered_items:
            max_count = max(item.get('interaction_count', 0) for item in filtered_items)
            if max_count > 0:
                for item in filtered_items:
                    item['score'] = item.get('interaction_count', 0) / max_count
        
        return filtered_items
////////////////////////////////////////////////////////////////////////////////

│   ├── content_based_recommender.py

////////////////////////////////////////////////////////////////////////////////
"""
Content-based recommender implementation.
Uses vector embeddings to find similar content.
"""
from typing import List, Dict, Any, Optional
import logging

from services.base_recommender import BaseRecommender
from data.repositories import ContentEmbeddingRepository
from config import DEFAULT_RECOMMENDATION_LIMIT, CONTENT_TYPES, MIN_SIMILARITY_SCORE

logger = logging.getLogger(__name__)

class ContentBasedRecommender(BaseRecommender):
    """
    Content-based recommendation strategy.
    Uses vector embeddings to find similar content based on content features.
    """
    
    def __init__(self):
        """Initialize the content-based recommender."""
        self.repository = ContentEmbeddingRepository()
    
    def get_recommendations(
        self, 
        user_id: Optional[str] = None,
        meal_id: Optional[str] = None,
        content_type: Optional[str] = None,
        limit: int = DEFAULT_RECOMMENDATION_LIMIT,
        min_similarity: float = MIN_SIMILARITY_SCORE,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        Get content-based recommendations.
        
        Args:
            user_id: Not used for content-based recommendations
            meal_id: The ID of the source meal
            content_type: The type of content ('meal', 'recipe')
            limit: Maximum number of recommendations
            min_similarity: Minimum similarity score threshold
            kwargs: Additional filters (not used for content-based)
            
        Returns:
            List of similar content items
        """
        if not meal_id or not content_type:
            logger.warning("Meal ID and content type required for content-based recommendations")
            return []
        
        if content_type not in CONTENT_TYPES:
            logger.warning(f"Invalid content type: {content_type}")
            return []
        
        # Get the embedding for the source content
        embedding = self.repository.get_embedding(meal_id, content_type)
        if not embedding:
            logger.warning(f"No embedding found for {content_type} with ID {meal_id}")
            return []
        
        # Find similar content
        exclude_ids = [meal_id]  # Exclude the source content
        similar_items = self.repository.find_similar_content(
            embedding, 
            content_type=content_type,
            exclude_ids=exclude_ids,
            limit=limit
        )
        
        # Filter by minimum similarity threshold
        filtered_items = [item for item in similar_items if item.get('similarity', 0) >= min_similarity]
        
        # Rename similarity to score for consistent interface
        for item in filtered_items:
            item['score'] = item.pop('similarity', 0)
        
        return filtered_items
    
    def get_similar_by_ingredients(
        self,
        meal_id: str,
        content_type: str,
        limit: int = DEFAULT_RECOMMENDATION_LIMIT
    ) -> List[Dict[str, Any]]:
        """
        Get meals similar by ingredients.
        
        Args:
            meal_id: The ID of the meal
            content_type: The type of content
            limit: Maximum number of results
            
        Returns:
            List of similar meals
        """
        similar_items = self.repository.get_similar_by_ingredients(
            meal_id=meal_id,
            content_type=content_type,
            limit=limit
        )
        
        # Rename similarity to score for consistent interface
        for item in similar_items:
            item['score'] = item.pop('similarity', 0)
        
        return similar_items
////////////////////////////////////////////////////////////////////////////////

│   ├── hybrid_recommender.py

////////////////////////////////////////////////////////////////////////////////
"""
Hybrid recommender implementation.
Combines multiple recommendation strategies to provide robust recommendations.
"""
from typing import List, Dict, Any, Optional
import logging

from services.base_recommender import BaseRecommender
from services.collaborative import CollaborativeRecommender
from services.content_based import ContentBasedRecommender
from services.popularity import PopularityRecommender
from services.item_based import ItemBasedRecommender
from data.repositories import InteractionRepository
from config import DEFAULT_RECOMMENDATION_LIMIT

logger = logging.getLogger(__name__)

class HybridRecommender(BaseRecommender):
    """
    Hybrid recommendation strategy.
    Combines multiple recommendation strategies with fallbacks:
    1. Collaborative filtering (user-based)
    2. Content-based recommendations
    3. Item-based collaborative filtering
    4. Popularity-based recommendations
    
    Each strategy contributes to the final recommendation list, with
    weights assigned to prioritize and blend the recommendations.
    """
    
    def __init__(self):
        """Initialize the hybrid recommender with various strategies."""
        self.collaborative_recommender = CollaborativeRecommender()
        self.content_based_recommender = ContentBasedRecommender()
        self.item_based_recommender = ItemBasedRecommender()
        self.popularity_recommender = PopularityRecommender()
        self.interaction_repository = InteractionRepository()
    
    def get_recommendations(
        self, 
        user_id: Optional[str] = None,
        meal_id: Optional[str] = None,
        content_type: Optional[str] = None,
        limit: int = DEFAULT_RECOMMENDATION_LIMIT,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        Get hybrid recommendations using multiple strategies with fallbacks.
        
        Args:
            user_id: The ID of the user for personalized recommendations
            meal_id: Optional content ID for similar content recommendations
            content_type: Optional content type filter
            limit: Maximum number of recommendations
            kwargs: Additional parameters like cuisine and dietary_restriction
            
        Returns:
            List of recommended items
        """
        all_recommendations = {}
        strategy_weights = {
            'collaborative': 1.0,
            'content': 0.8,
            'item_based': 0.7,
            'popularity': 0.5
        }
        
        # Step 1: Try collaborative filtering if we have a user_id
        if user_id:
            collaborative_items = self.collaborative_recommender.get_recommendations(
                user_id=user_id,
                content_type=content_type,
                limit=limit * 2,  # Request more items for better blending
                **kwargs
            )
            
            # Add to all recommendations with collaborative weight
            for item in collaborative_items:
                item_id = item.get('id')
                if item_id:
                    score = item.get('score', 0.5) * strategy_weights['collaborative']
                    if item_id in all_recommendations:
                        all_recommendations[item_id]['score'] = max(
                            all_recommendations[item_id]['score'],
                            score
                        )
                    else:
                        item['score'] = score
                        all_recommendations[item_id] = item
            
            logger.info(f"Collaborative filtering added {len(collaborative_items)} items")
        
        # Step 2: Try content-based if we have user interactions or meal_id
        recent_meal_id = meal_id
        recent_content_type = content_type
        
        # If no meal_id but we have user_id, get their most recent interaction
        if not meal_id and user_id:
            recent_interactions = self.interaction_repository.get_user_recent_interactions(
                user_id=user_id,
                content_type=content_type,
                limit=1
            )
            
            if recent_interactions:
                recent = recent_interactions[0]
                recent_meal_id = recent['meal_id']
                recent_content_type = recent['content_type']
        
        # If we have a meal to base content similarity on, get recommendations
        if recent_meal_id and recent_content_type:
            content_based_items = self.content_based_recommender.get_recommendations(
                meal_id=recent_meal_id,
                content_type=recent_content_type,
                limit=limit * 2,  # Request more items for better blending
                **kwargs
            )
            
            # Add to all recommendations with content-based weight
            for item in content_based_items:
                item_id = item.get('id')
                if item_id:
                    score = item.get('score', 0.5) * strategy_weights['content']
                    if item_id in all_recommendations:
                        all_recommendations[item_id]['score'] = max(
                            all_recommendations[item_id]['score'],
                            score
                        )
                    else:
                        item['score'] = score
                        all_recommendations[item_id] = item
            
            logger.info(f"Content-based filtering added {len(content_based_items)} items")
        
        # Step 3: Try item-based collaborative filtering if we have user_id
        if user_id:
            item_based_items = self.item_based_recommender.get_recommendations(
                user_id=user_id,
                content_type=content_type,
                limit=limit * 2,  # Request more items for better blending
                **kwargs
            )
            
            # Add to all recommendations with item-based weight
            for item in item_based_items:
                item_id = item.get('id')
                if item_id:
                    score = item.get('score', 0.5) * strategy_weights['item_based']
                    if item_id in all_recommendations:
                        all_recommendations[item_id]['score'] = max(
                            all_recommendations[item_id]['score'],
                            score
                        )
                    else:
                        item['score'] = score
                        all_recommendations[item_id] = item
            
            logger.info(f"Item-based filtering added {len(item_based_items)} items")
        
        # Step 4: Add popularity-based recommendations to fill any gaps
        popularity_items = self.popularity_recommender.get_recommendations(
            content_type=content_type,
            limit=limit * 2,  # Request more items for better blending
            **kwargs
        )
        
        # Add to all recommendations with popularity weight
        for item in popularity_items:
            item_id = item.get('id')
            if item_id:
                score = item.get('score', 0.5) * strategy_weights['popularity']
                if item_id in all_recommendations:
                    # Only use popularity as a boost, not a replacement
                    all_recommendations[item_id]['score'] += score * 0.2
                else:
                    item['score'] = score
                    all_recommendations[item_id] = item
        
        logger.info(f"Popularity-based filtering added {len(popularity_items)} items")
        
        # Convert dict to list, sort by score, and limit results
        recommended_items = list(all_recommendations.values())
        recommended_items.sort(key=lambda x: x.get('score', 0), reverse=True)
        
        logger.info(f"Hybrid recommender generated {len(recommended_items)} items total")
        return recommended_items[:limit]
////////////////////////////////////////////////////////////////////////////////

│   ├── item_based_recommender.py

////////////////////////////////////////////////////////////////////////////////
"""
Item-based collaborative filtering recommender implementation.
Recommends items based on co-occurrence patterns with items the user has interacted with.
"""
from typing import List, Dict, Any, Optional
import logging

from services.base_recommender import BaseRecommender
from data.repositories import InteractionRepository
from config import DEFAULT_RECOMMENDATION_LIMIT
from data.queries import FIND_SIMILAR_ITEMS
from data.database import execute_query

logger = logging.getLogger(__name__)

class ItemBasedRecommender(BaseRecommender):
    """
    Item-based collaborative filtering recommendation strategy.
    Finds items similar to those the user has already interacted with,
    based on how frequently items co-occur in user interactions.
    """
    
    def __init__(self):
        """Initialize the item-based recommender."""
        self.repository = InteractionRepository()
    
    def get_recommendations(
        self, 
        user_id: Optional[str] = None,
        meal_id: Optional[str] = None,
        content_type: Optional[str] = None,
        limit: int = DEFAULT_RECOMMENDATION_LIMIT,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        Get item-based collaborative filtering recommendations.
        
        Args:
            user_id: The ID of the user
            meal_id: Optional specific meal ID to find similar items for
            content_type: Optional content type filter
            limit: Maximum number of recommendations
            kwargs: Additional filters (cuisine, dietary_restriction)
            
        Returns:
            List of recommended items based on item similarity
        """
        if not user_id and not meal_id:
            logger.warning("Either user_id or meal_id required for item-based recommendations")
            return []
        
        # If meal_id is provided, use it directly to find similar items
        if meal_id:
            return self._get_similar_items(meal_id, content_type, limit)
        
        # Otherwise, use the user's recent interactions to find similar items
        return self._get_user_item_based_recommendations(user_id, content_type, limit, **kwargs)
    
    def _get_similar_items(
        self,
        meal_id: str,
        content_type: Optional[str] = None,
        limit: int = DEFAULT_RECOMMENDATION_LIMIT
    ) -> List[Dict[str, Any]]:
        """
        Find items similar to a specific meal item based on co-occurrence patterns.
        
        Args:
            meal_id: The ID of the meal to find similar items for
            content_type: Optional content type filter
            limit: Maximum number of similar items to return
            
        Returns:
            List of similar items
        """
        # Execute SQL to find items that frequently co-occur with the given meal_id
        params = {
            "meal_id": meal_id,
            "limit": limit
        }
        
        type_filter = ""
        if content_type:
            type_filter = "AND ri2.content_type = :content_type"
            params["content_type"] = content_type
        
        # Format the query with the type filter
        formatted_query = FIND_SIMILAR_ITEMS.format(
            type_filter=type_filter
        )
        
        result = execute_query(
            formatted_query,
            params
        )
        
        similar_items = []
        for row in result:
            similar_items.append({
                "id": row[0],
                "content_type": row[1],
                "title": row[2],
                "co_occurrence_count": row[3],
                "score": row[3] / 10.0  # Normalize to 0-1 range (approximate)
            })
        
        return similar_items
    
    def _get_user_item_based_recommendations(
        self,
        user_id: str,
        content_type: Optional[str] = None,
        limit: int = DEFAULT_RECOMMENDATION_LIMIT,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        Get item-based recommendations for a user by finding items similar
        to those they've already interacted with.
        
        Args:
            user_id: The ID of the user
            content_type: Optional content type filter
            limit: Maximum number of recommendations
            kwargs: Additional filters (cuisine, dietary_restriction)
            
        Returns:
            List of recommended items
        """
        # Get user's recent interactions
        recent_interactions = self.repository.get_user_recent_interactions(
            user_id=user_id,
            content_type=content_type,
            limit=5  # Use top 5 recent interactions
        )
        
        if not recent_interactions:
            logger.info(f"No recent interactions found for user {user_id}")
            return []
        
        all_recommendations = []
        user_items = [interaction["meal_id"] for interaction in recent_interactions]
        
        # For each item the user has interacted with, find similar items
        for interaction in recent_interactions:
            meal_id = interaction["meal_id"]
            similar_items = self._get_similar_items(
                meal_id=meal_id,
                content_type=content_type,
                limit=limit
            )
            
            # Filter out items the user has already interacted with
            filtered_items = [item for item in similar_items if item["id"] not in user_items]
            all_recommendations.extend(filtered_items)
        
        # Remove duplicates by creating a dictionary keyed by item ID
        unique_items = {}
        for item in all_recommendations:
            item_id = item["id"]
            if item_id not in unique_items or item.get("score", 0) > unique_items[item_id].get("score", 0):
                unique_items[item_id] = item
        
        # Sort by score and limit results
        sorted_items = sorted(
            unique_items.values(), 
            key=lambda x: x.get("score", 0), 
            reverse=True
        )
        
        # Apply additional filters if specified
        filtered_items = sorted_items
        
        # Filter by cuisine if specified
        cuisine = kwargs.get('cuisine')
        if cuisine and filtered_items:
            # This would require additional logic to filter by cuisine
            logger.info(f"Filtering by cuisine: {cuisine}")
        
        # Filter by dietary restriction if specified
        dietary_restriction = kwargs.get('dietary_restriction')
        if dietary_restriction and filtered_items:
            # This would require additional logic to filter by dietary restriction
            logger.info(f"Filtering by dietary restriction: {dietary_restriction}")
        
        return filtered_items[:limit]
////////////////////////////////////////////////////////////////////////////////

│   └── popularity_recommender.py

////////////////////////////////////////////////////////////////////////////////
"""
Popularity-based recommender implementation.
Recommends trending or popular content based on interaction counts.
"""
from typing import List, Dict, Any, Optional
import logging

from services.base_recommender import BaseRecommender
from data.repositories import InteractionRepository
from config import DEFAULT_RECOMMENDATION_LIMIT, ALLOWED_TRENDING_WINDOWS

logger = logging.getLogger(__name__)

class PopularityRecommender(BaseRecommender):
    """
    Popularity-based recommendation strategy.
    Recommends trending or popular content based on interaction counts.
    This is a non-personalized strategy that can be used as a fallback.
    """
    
    def __init__(self):
        """Initialize the popularity recommender."""
        self.repository = InteractionRepository()
    
    def get_recommendations(
        self, 
        user_id: Optional[str] = None,
        meal_id: Optional[str] = None,
        content_type: Optional[str] = None,
        limit: int = DEFAULT_RECOMMENDATION_LIMIT,
        time_window: str = "day",
        exclude_ids: List[str] = None,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        Get popularity-based recommendations.
        
        Args:
            user_id: Optional user ID (used for filtering recommendations)
            meal_id: Not used for popularity recommendations
            content_type: Optional content type filter ('meal', 'recipe', 'all')
            limit: Maximum number of recommendations
            time_window: Time window for trending content ('day', 'week', 'month')
            exclude_ids: Optional list of content IDs to exclude
            kwargs: Additional filters (cuisine, dietary_restriction)
            
        Returns:
            List of popular content items
        """
        if time_window not in ALLOWED_TRENDING_WINDOWS:
            logger.warning(f"Invalid time window: {time_window}. Using 'day' instead.")
            time_window = "day"
        
        content_type_filter = content_type if content_type else 'all'
        
        # Get trending content
        popular_items = self.repository.get_trending_content(
            content_type=content_type_filter,
            time_window=time_window,
            limit=limit * 2  # Request more items to account for filtering
        )
        
        # Filter out excluded IDs if specified
        if exclude_ids:
            popular_items = [item for item in popular_items if item["id"] not in exclude_ids]
        
        # Apply additional filters if specified
        filtered_items = popular_items
        
        # Filter by cuisine if specified
        cuisine = kwargs.get('cuisine')
        if cuisine and filtered_items:
            # This would require additional logic to filter by cuisine
            logger.info(f"Filtering by cuisine: {cuisine}")
        
        # Filter by dietary restriction if specified
        dietary_restriction = kwargs.get('dietary_restriction')
        if dietary_restriction and filtered_items:
            # This would require additional logic to filter by dietary restriction
            logger.info(f"Filtering by dietary restriction: {dietary_restriction}")
        
        # Normalize popularity scores to 0-1 range
        if filtered_items:
            max_popularity = max(item.get('popularity', 0) for item in filtered_items)
            if max_popularity > 0:
                for item in filtered_items:
                    item['score'] = item.get('popularity', 0) / max_popularity
        
        return filtered_items[:limit]
    
    def get_cuisine_recommendations(
        self,
        cuisine_id: str,
        limit: int = DEFAULT_RECOMMENDATION_LIMIT
    ) -> List[Dict[str, Any]]:
        """
        Get recommendations for a specific cuisine.
        
        Args:
            cuisine_id: The ID of the cuisine
            limit: Maximum number of recommendations
            
        Returns:
            List of meals in the cuisine
        """
        return self.repository.get_cuisine_recommendations(
            cuisine_id=cuisine_id,
            limit=limit
        )
    
    def get_dietary_recommendations(
        self,
        dietary_restriction_id: str,
        limit: int = DEFAULT_RECOMMENDATION_LIMIT
    ) -> List[Dict[str, Any]]:
        """
        Get recommendations based on dietary restrictions.
        
        Args:
            dietary_restriction_id: The ID of the dietary restriction
            limit: Maximum number of recommendations
            
        Returns:
            List of meals matching the dietary restriction
        """
        return self.repository.get_dietary_recommendations(
            dietary_restriction_id=dietary_restriction_id,
            limit=limit
        )
////////////////////////////////////////////////////////////////////////////////

├── setup
│   ├── __init__.py

////////////////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////////////////

│   └── setup.py

////////////////////////////////////////////////////////////////////////////////
"""
Database setup script.
Creates necessary database tables and indexes for the recommendation system.
"""
import logging
from sqlalchemy import text

from data.database import execute_query, get_transaction, test_connection
from config import EMBEDDING_DIMENSION
from data.queries import (
    ENABLE_PGVECTOR,
    CREATE_CONTENT_EMBEDDINGS_TABLE,
    CREATE_EMBEDDINGS_INDEX,
    CREATE_INTERACTIONS_TABLE,
    CREATE_INTERACTIONS_INDEXES,
    CREATE_CUISINE_TABLE,
    CREATE_DIETARY_RESTRICTION_TABLE,
    CREATE_USER_DIETARY_PREFERENCE_TABLE,
    CREATE_MEAL_DIETARY_RESTRICTION_TABLE,
    CREATE_INGREDIENT_TABLE,
    CREATE_MEAL_INGREDIENT_TABLE,
    INSERT_DEFAULT_CUISINES,
    INSERT_DEFAULT_DIETARY_RESTRICTIONS
)

logger = logging.getLogger(__name__)

def create_recommendation_tables():
    """Create all necessary tables and indexes for the recommendation system."""
    logger.info("Creating recommendation database tables and indexes...")
    
    try:
        with get_transaction() as conn:
            # Enable pgvector extension
            conn.execute(text(ENABLE_PGVECTOR))
            
            # Create a separate table for content embeddings
            # Format the query with the embedding dimension
            formatted_embeddings_table = CREATE_CONTENT_EMBEDDINGS_TABLE.format(
                embedding_dimension=EMBEDDING_DIMENSION
            )
            conn.execute(text(formatted_embeddings_table))
            
            # Create index for vector search
            conn.execute(text(CREATE_EMBEDDINGS_INDEX))
            
            # Create interactions table
            conn.execute(text(CREATE_INTERACTIONS_TABLE))
            
            # Create indexes for quick lookups
            conn.execute(text(CREATE_INTERACTIONS_INDEXES))
            
            # Create reference tables
            conn.execute(text(CREATE_CUISINE_TABLE))
            conn.execute(text(CREATE_DIETARY_RESTRICTION_TABLE))
            conn.execute(text(CREATE_USER_DIETARY_PREFERENCE_TABLE))
            conn.execute(text(CREATE_MEAL_DIETARY_RESTRICTION_TABLE))
            conn.execute(text(CREATE_INGREDIENT_TABLE))
            conn.execute(text(CREATE_MEAL_INGREDIENT_TABLE))
            
            # Insert default reference data
            conn.execute(text(INSERT_DEFAULT_CUISINES))
            conn.execute(text(INSERT_DEFAULT_DIETARY_RESTRICTIONS))
        
        logger.info("Database tables and indexes created successfully")
        return True
    except Exception as e:
        logger.error(f"Error creating database tables: {e}")
        return False

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # Test database connection
    if test_connection():
        # Create tables
        success = create_recommendation_tables()
        if success:
            logger.info("Database setup completed successfully")
        else:
            logger.error("Database setup failed")
    else:
        logger.error("Database connection test failed. Check your DATABASE_URL in .env file.")
////////////////////////////////////////////////////////////////////////////////

├── start.sh

////////////////////////////////////////////////////////////////////////////////
#!/bin/bash
# start.sh
# Startup script for the meal recommendation service

# Set the directory to the script's location
DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
cd $DIR

# Function to check if a Python module exists
module_exists() {
    python3 -c "import $1" 2>/dev/null
    return $?
}

# Check for required Python packages
echo "Checking for required Python packages..."
required_packages=(
    "fastapi" 
    "uvicorn" 
    "sqlalchemy" 
    "psycopg2-binary" 
    "sentence-transformers" 
    "schedule" 
    "python-dotenv"
    "numpy"
)
missing_packages=()

for package in "${required_packages[@]}"; do
    if ! module_exists $package; then
        missing_packages+=($package)
    fi
done

# Install missing packages if any
if [ ${#missing_packages[@]} -ne 0 ]; then
    echo "Installing missing packages: ${missing_packages[*]}"
    pip install "${missing_packages[@]}"
fi

# Check if pgvector extension is installed in PostgreSQL
echo "Checking pgvector extension..."
python3 -c "
from data.database import execute_query
try:
    result = execute_query('SELECT COUNT(*) FROM pg_extension WHERE extname = \\'vector\\'')
    count = result.fetchone()[0]
    if count == 0:
        print('pgvector extension is not installed in the database.')
        print('You may need to run: CREATE EXTENSION vector;')
    else:
        print('pgvector extension is properly installed.')
except Exception as e:
    print(f'Error checking pgvector extension: {e}')
"

# Create necessary database tables
echo "Setting up database tables..."
python3 -m setup

# Generate initial embeddings
echo "Generating initial embeddings..."
python3 -c "
from embeddings.generator import EmbeddingGenerator
generator = EmbeddingGenerator()
result = generator.generate_all_embeddings()
print(f'Initial embeddings generated: {result}')
"

# Start the API server
echo "Starting API server..."
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
////////////////////////////////////////////////////////////////////////////////

└── util
    ├── __init__.py

////////////////////////////////////////////////////////////////////////////////

////////////////////////////////////////////////////////////////////////////////

    └── scheduler.py

////////////////////////////////////////////////////////////////////////////////
"""
Background task scheduler for meal recommendation service.
Manages periodic tasks for embedding generation and other maintenance operations.
"""
import schedule
import time
import threading
import logging
import signal
import sys
from typing import Callable, Dict, List
from datetime import datetime, timedelta

from embeddings.generator import EmbeddingGenerator
from config import (
    EMBEDDING_GENERATION_INTERVAL,
    SCHEDULER_SLEEP_INTERVAL,
    LOG_LEVEL,
    LOG_FORMAT
)

logger = logging.getLogger(__name__)

# Track running tasks
_running_tasks: Dict[str, bool] = {}
_task_last_run: Dict[str, datetime] = {}
_task_durations: Dict[str, List[float]] = {}
_scheduler_thread: threading.Thread = None
_stop_event = threading.Event()

def timed_task(task_name: str) -> Callable:
    """
    Decorator to time tasks and track their execution.
    
    Args:
        task_name: Name of the task to track
        
    Returns:
        Decorated function
    """
    def decorator(func: Callable) -> Callable:
        def wrapper(*args, **kwargs):
            # Mark task as running
            _running_tasks[task_name] = True
            _task_last_run[task_name] = datetime.now()
            
            start_time = time.time()
            logger.info(f"Starting task: {task_name}")
            
            try:
                result = func(*args, **kwargs)
                end_time = time.time()
                duration = end_time - start_time
                
                # Track task duration
                if task_name not in _task_durations:
                    _task_durations[task_name] = []
                
                _task_durations[task_name].append(duration)
                
                # Keep only the last 10 durations for average calculation
                if len(_task_durations[task_name]) > 10:
                    _task_durations[task_name] = _task_durations[task_name][-10:]
                
                avg_duration = sum(_task_durations[task_name]) / len(_task_durations[task_name])
                
                logger.info(f"Task {task_name} completed in {duration:.2f}s (avg: {avg_duration:.2f}s)")
                return result
            except Exception as e:
                logger.error(f"Error in task {task_name}: {e}")
                raise
            finally:
                # Mark task as not running
                _running_tasks[task_name] = False
        return wrapper
    return decorator

@timed_task("embedding_generation")
def run_embedding_generation():
    """
    Generate embeddings for meals and recipes that don't have them yet.
    This task runs periodically to ensure all content has embeddings.
    """
    try:
        generator = EmbeddingGenerator()
        result = generator.generate_all_embeddings()
        
        meals_count = result.get('meals', 0)
        recipes_count = result.get('recipes', 0)
        total_count = meals_count + recipes_count
        
        if total_count > 0:
            logger.info(f"Generated embeddings for {meals_count} meals and {recipes_count} recipes")
        else:
            logger.info("No new content requiring embeddings")
        
        return result
    except Exception as e:
        logger.error(f"Error during embedding generation: {e}")
        return {"error": str(e)}

def get_task_status() -> Dict:
    """
    Get the status of scheduled tasks.
    
    Returns:
        Dictionary with task status information
    """
    status = {}
    
    for task_name in _task_last_run:
        status[task_name] = {
            "running": _running_tasks.get(task_name, False),
            "last_run": _task_last_run[task_name].isoformat() if task_name in _task_last_run else None,
            "average_duration": None
        }
        
        if task_name in _task_durations and _task_durations[task_name]:
            avg_duration = sum(_task_durations[task_name]) / len(_task_durations[task_name])
            status[task_name]["average_duration"] = f"{avg_duration:.2f}s"
            
        if task_name in _task_last_run:
            time_since_last_run = datetime.now() - _task_last_run[task_name]
            status[task_name]["time_since_last_run"] = f"{time_since_last_run.total_seconds():.0f}s"
    
    return status

def run_scheduler():
    """
    Run the scheduler loop to execute pending tasks.
    This function runs in a separate thread and periodically checks
    for tasks that need to be executed.
    """
    while not _stop_event.is_set():
        schedule.run_pending()
        time.sleep(SCHEDULER_SLEEP_INTERVAL)

def stop_scheduler():
    """Stop the scheduler thread."""
    logger.info("Stopping scheduler...")
    _stop_event.set()
    
    if _scheduler_thread and _scheduler_thread.is_alive():
        _scheduler_thread.join(timeout=5)
        
    logger.info("Scheduler stopped")

def handle_exit_signal(signum, frame):
    """Handle exit signals to gracefully stop the scheduler."""
    logger.info(f"Received signal {signum}, shutting down gracefully...")
    stop_scheduler()
    sys.exit(0)

def start_scheduler():
    """
    Configure and start the scheduler in a background thread.
    Sets up signal handlers for graceful shutdown.
    
    Returns:
        The scheduler thread
    """
    global _scheduler_thread
    
    # Register signal handlers for graceful shutdown
    signal.signal(signal.SIGINT, handle_exit_signal)
    signal.signal(signal.SIGTERM, handle_exit_signal)
    
    # Clear any existing schedules
    schedule.clear()
    
    # Schedule embedding generation job
    schedule.every(EMBEDDING_GENERATION_INTERVAL).minutes.do(run_embedding_generation)
    logger.info(f"Scheduled embedding generation every {EMBEDDING_GENERATION_INTERVAL} minutes")
    
    # Initialize tracking dictionaries
    _running_tasks["embedding_generation"] = False
    _task_last_run["embedding_generation"] = datetime.now() - timedelta(days=1)  # Set to past time
    
    # Reset stop event
    _stop_event.clear()
    
    # Start scheduler in background thread
    _scheduler_thread = threading.Thread(target=run_scheduler, name="SchedulerThread")
    _scheduler_thread.daemon = True
    _scheduler_thread.start()
    
    logger.info("Scheduler started in background thread")
    return _scheduler_thread

if __name__ == "__main__":
    # Configure logging
    logging.basicConfig(
        level=getattr(logging, LOG_LEVEL),
        format=LOG_FORMAT
    )
    
    # Run immediately on first execution
    logger.info("Running initial embedding generation")
    run_embedding_generation()
    
    # Start scheduler
    thread = start_scheduler()
    
    logger.info("Scheduler running. Press Ctrl+C to exit.")
    try:
        # Keep the main thread alive
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        stop_scheduler()
        logger.info("Scheduler stopped.")
////////////////////////////////////////////////////////////////////////////////

